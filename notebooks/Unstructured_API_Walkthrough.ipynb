{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Unstructured API Walkthrough"
      ],
      "metadata": {
        "id": "KUfA8yHXXb3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This walkthrough provides you with deep, hands-on experience with the [Unstructured API](https://docs.unstructured.io/api-reference/overview). As you follow along, you will learn how to use many of Unstructured's features for\n",
        "[partitioning](https://docs.unstructured.io/ui/partitioning),\n",
        "[enriching](https://docs.unstructured.io/ui/enriching/overview),\n",
        "[chunking](https://docs.unstructured.io/ui/chunking),\n",
        "and [embedding](https://docs.unstructured.io/ui/embedding).\n",
        "These features are optimized for turning your source documents and data into information that is well-tuned for\n",
        "[retrieval-augmented generation (RAG)](https://unstructured.io/blog/rag-whitepaper),\n",
        "[agentic AI](https://unstructured.io/problems-we-solve#powering-agentic-ai),\n",
        "and [model fine-tuning](https://www.geeksforgeeks.org/deep-learning/what-is-fine-tuning/).\n",
        "\n",
        "This walkthrough uses two sample files to demonstrate how Unstructured identifies and processes content such as image, graphs, complex tables, non-English characters, and handwriting. These files, which are available for you to download to your local machine, include:\n",
        "\n",
        "- Wang, Z., Liu, X., & Zhang, M. (2022, November 23). _Breaking the Representation Bottleneck of Chinese Characters: Neural Machine Translation with Stroke Sequence Modeling_. arXiv.org. https://arxiv.org/pdf/2211.12781. This 12-page PDF file features English and non-English characters, images, graphs, and complex tables. Throughout this walkthrough, this file's title is shortened to “Chinese characters” for brevity.\n",
        "- United States Central Security Service. (2012, January 27). _National Cryptologic Museum Opens New Exhibit on Dr. John Nash_. United States National Security Agency. https://courses.csail.mit.edu/6.857/2012/files/H03-Cryptosystem-proposed-by-Nash.pdf. This PDF file features English handwriting and scanned images of documents. Throughout this walkthrough, this file's title is shortened to “Nash letters” for brevity.\n",
        "\n",
        "If you are not able to complete any of the following steps, contact Unstructured Support at [support@unstructured.io](mailto:support@unstructured.io).\n",
        "\n",
        "---\n",
        ">\n",
        "> 💡 _What's this?_\n",
        ">\n",
        "> As you move through this walkthrough, you will notice tips like this one.\n",
        "> These tips are designed to help expand your knowledge about Unstructured as\n",
        "> you go. Feel free to skip these tips for now if you are in a hurry. You can\n",
        "> always return to them later to learn more.\n",
        ">\n",
        "---"
      ],
      "metadata": {
        "id": "KBvJMW2eXkvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Requirements"
      ],
      "metadata": {
        "id": "vap1byT_cpuq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run this notebook, you will need:\n",
        "\n",
        "- An Unstructured account. To sign up for an account, go to https://unstructured.io/?modal=try-for-free. After you sign up, you are immediately signed in to your new account, at https://platform.unstructured.io.\n",
        "- An Unstructured API key, as follows:\n",
        "\n",
        "  1. After you are signed in to your account, on the sidebar click **API Keys**.\n",
        "  2. Click **Generate New Key**.\n",
        "  3. Enter some meaningful display name for the key, and then click **Continue**.\n",
        "  4. Next to the new key's name, click the **Copy** icon. The key's value is copied to your system's clipboard. If you lose this key, simply return to the list and click **Copy** again.\n",
        "\n",
        "- One or more local files for Unstructured to process. This notebook assumes that the local files you want to process are in a subfolder that is accessible from this notebook. The easiest and fastest way to create this subfolder is as follows:\n",
        "\n",
        "  1. On this notebook's sidebar, click the folder (**Files**) icon. By default, the **Files** pane will show all files and subfolders within the `/content` folder.\n",
        "  2. Right-click in a blank area anywhere below the existing list of subfolders and files in the **Files** pane, and then click **New folder**.\n",
        "  3. Enter a name for the new subfolder within `/content`. This notebook assumes the subfolder is named `input`.\n",
        "  4. To upload files to this subfolder, do the following:\n",
        "\n",
        "     a. Rest your mouse pointer on the `input` subfolder.<br/>\n",
        "     b. Click the ellipsis (three dots) icon, and then click **Upload**.<br/>\n",
        "     c. Browse to and select the \"Chinese characters\" and \"Nash letters\" files on your local machine that you want to upload to this `input` subfolder.<br/>\n",
        "\n",
        "- A destination subfolder for Unstructured to send its processed results to. This notebook assumes that the destination folder is accessible from this notebook. The easiest and fastest way to create this folder is as follows:\n",
        "\n",
        "  1. If the **Files** pane is not already open, then on this notebook's sidebar, click the folder (**Files**) icon. By default, the **Files** pane will show all files and subfolders within the `/content` folder.\n",
        "  2. Right-click in a blank area anywhere below the existing list of subfolders and files in the **Files** pane, and then click **New folder**.\n",
        "  3. Enter a name for the new subfolder within `/content`. This notebook assumes the subfolder is named `output`.\n",
        "\n",
        "---\n",
        ">\n",
        "> ⚠️ **Warning**: Any files that you upload to these `input` or `output`\n",
        "> subfolders will be deleted whenever Google Colab disconnects or resets, for\n",
        "> example due to inactivity, manual restart, or session timeout.\n",
        ">\n",
        "---"
      ],
      "metadata": {
        "id": "LvZA74_acs2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Create a custom workflow"
      ],
      "metadata": {
        "id": "k5vLmPixcbBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, you create a custom [workflow](https://docs.unstructured.io/api-reference/workflow/workflows) in your Unstructured account.\n",
        "Workflows are defined sequences of processes that automate the flow of data from your source documents and data into Unstructured for processing. Unstructured then sends its processed data over into your destination file storage locations, databases, and vector stores. Your RAG apps, agents, and models can then use this processed data in those destinations to do things more quickly and accurately such as\n",
        "[answering users' questions](https://learn.microsoft.com/en-us/azure/developer/ai/advanced-retrieval-augmented-generation),\n",
        "[automating business processes](https://unstructured.io/problems-we-solve#business-process-automation),\n",
        "and [expanding your organization's available body of knowledge](http://knowledgemanagement.ie/the-critical-role-of-knowledge-management-as-a-foundation-for-llms-and-ai/).\n",
        "\n",
        "---\n",
        ">\n",
        "> 💡 _Which kinds of sources and destinations does Unstructured support?_\n",
        ">\n",
        "> Unstructured can connect to many types of sources and destinations including\n",
        "> file storage services such as Amazon S3 and Google Cloud Storage; databases\n",
        "> such as PostgreSQL; and vector storage and database services such as MongoDB\n",
        "> Atlas and Pinecone.\n",
        ">\n",
        "> See the full list of [supported source connectors](https://docs.unstructured.io/api-reference/workflow/sources/overview) and [supported destination connectors](https://docs.unstructured.io/api-reference/workflow/destinations/overview).\n",
        ">\n",
        "---\n",
        ">\n",
        "> 💡 _Which kinds of files does Unstructured support?_\n",
        ">\n",
        "> Unstructured can process a wide variety of file types including PDFs, word\n",
        "> processing documents, spreadsheets, slide decks, HTML, image files, emails,\n",
        "> and more.\n",
        ">\n",
        "> See the full list of [supported file types](https://docs.unstructured.io/api-reference/supported-file-types).\n",
        ">\n",
        "---"
      ],
      "metadata": {
        "id": "AZSAI8VrMk2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. In the following cell, replace `<your-unstructured-api-key>` with your pasted Unstructured API key's value and then run the cell, which sets the constant `UNSTRUCTURED_API_KEY` to your API key's value."
      ],
      "metadata": {
        "id": "fnjd_M7gRDHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UNSTRUCTURED_API_KEY = \"<your-unstructured-api-key>\""
      ],
      "metadata": {
        "id": "TIjnOLOnRZsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Run the following cell, which installs the `unstructured-client` and `datetime` libraries. These libraries are required for making HTTP requests to the Unstructured API and for assigning unique asset names in this example, respectively."
      ],
      "metadata": {
        "id": "z7lxOtcKRaxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U unstructured-client datetime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dod8E_OpRl64",
        "outputId": "37180df3-074a-47c6-c6ee-9b8eb2d96e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unstructured-client\n",
            "  Downloading unstructured_client-0.42.3-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting datetime\n",
            "  Downloading DateTime-5.5-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.12/dist-packages (from unstructured-client) (24.1.0)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.12/dist-packages (from unstructured-client) (43.0.3)\n",
            "Requirement already satisfied: httpcore>=1.0.9 in /usr/local/lib/python3.12/dist-packages (from unstructured-client) (1.0.9)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from unstructured-client) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=2.11.2 in /usr/local/lib/python3.12/dist-packages (from unstructured-client) (2.11.9)\n",
            "Collecting pypdf>=4.0 (from unstructured-client)\n",
            "  Downloading pypdf-6.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from unstructured-client) (1.0.0)\n",
            "Collecting zope.interface (from datetime)\n",
            "  Downloading zope_interface-8.0.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from datetime) (2025.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.1->unstructured-client) (2.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpcore>=1.0.9->unstructured-client) (2025.8.3)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore>=1.0.9->unstructured-client) (0.16.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->unstructured-client) (4.10.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->unstructured-client) (3.10)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.2->unstructured-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.2->unstructured-client) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.2->unstructured-client) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.2->unstructured-client) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from requests-toolbelt>=1.0.0->unstructured-client) (2.32.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client) (2.23)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.1->requests-toolbelt>=1.0.0->unstructured-client) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.1->requests-toolbelt>=1.0.0->unstructured-client) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->unstructured-client) (1.3.1)\n",
            "Downloading unstructured_client-0.42.3-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.8/207.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DateTime-5.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-6.1.1-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.5/323.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zope_interface-8.0.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (264 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.7/264.7 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: zope.interface, pypdf, datetime, unstructured-client\n",
            "Successfully installed datetime-5.5 pypdf-6.1.1 unstructured-client-0.42.3 zope.interface-8.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Run the following cell, which creates an Unstructured custom workflow with a single node for partitioning. This workflow uses the **High Res** [partitioning](https://docs.unstructured.io/ui/partitioning) strategy to turn the contents of your documents and semi-structured data into a data format that is fine-tuned for well-tuned for retrieval-augmented generation (RAG), agentic AI, and model fine-tuning.\n",
        "\n",
        "   [Learn more about this code](https://docs.unstructured.io/api-reference/workflow/overview#create-a-workflow)."
      ],
      "metadata": {
        "id": "WMvIaw_pTwWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "from unstructured_client import UnstructuredClient\n",
        "from unstructured_client.models.shared import (\n",
        "    WorkflowNode,\n",
        "    CreateWorkflow,\n",
        "    WorkflowType\n",
        ")\n",
        "from unstructured_client.models.operations import CreateWorkflowRequest\n",
        "\n",
        "with UnstructuredClient(api_key_auth=UNSTRUCTURED_API_KEY) as client:\n",
        "    partition_node = WorkflowNode(\n",
        "        name=\"Partitioner\",\n",
        "        subtype=\"unstructured_api\",\n",
        "        type=\"partition\",\n",
        "        settings={\n",
        "            \"strategy\": \"hi_res\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    workflow = CreateWorkflow(\n",
        "        name=f\"api-demo-workflow-{datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")}\",\n",
        "        workflow_type=WorkflowType.CUSTOM,\n",
        "        workflow_nodes=[\n",
        "            partition_node\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    response = client.workflows.create_workflow(\n",
        "        request=CreateWorkflowRequest(\n",
        "            create_workflow=workflow\n",
        "        )\n",
        "    )\n",
        "\n",
        "    print(f\"Workflow details:\\n---\\n{response.workflow_information.model_dump_json(indent=4)}\")\n",
        "\n",
        "    WORKFLOW_ID = response.workflow_information.id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LDu8fU8Tyrf",
        "outputId": "dfbd1acd-91a8-417d-8226-3602b818bc92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workflow details:\n",
            "---\n",
            "{\n",
            "    \"created_at\": \"2025-09-30T18:04:14.558164Z\",\n",
            "    \"destinations\": [],\n",
            "    \"id\": \"ca99f800-8746-43e1-8f92-b6e36dbd22f8\",\n",
            "    \"name\": \"api-demo-workflow-2025-09-30-18-04-14\",\n",
            "    \"sources\": [],\n",
            "    \"status\": \"active\",\n",
            "    \"workflow_nodes\": [\n",
            "        {\n",
            "            \"name\": \"Partitioner\",\n",
            "            \"subtype\": \"unstructured_api\",\n",
            "            \"type\": \"partition\",\n",
            "            \"id\": \"1931bdfa-0901-4d58-baaf-c710fa4b34b3\",\n",
            "            \"settings\": {\n",
            "                \"strategy\": \"hi_res\",\n",
            "                \"include_page_breaks\": false,\n",
            "                \"pdf_infer_table_structure\": false,\n",
            "                \"exclude_elements\": null,\n",
            "                \"xml_keep_tags\": false,\n",
            "                \"encoding\": \"utf-8\",\n",
            "                \"extract_image_block_types\": [\n",
            "                    \"image\",\n",
            "                    \"table\"\n",
            "                ]\n",
            "            }\n",
            "        }\n",
            "    ],\n",
            "    \"reprocess_all\": true,\n",
            "    \"schedule\": {\n",
            "        \"crontab_entries\": []\n",
            "    },\n",
            "    \"updated_at\": \"2025-09-30T18:04:14.568643Z\",\n",
            "    \"workflow_type\": \"custom\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        ">\n",
        "> 💡 _What other kinds of settings can I set for my workflow?_\n",
        ">\n",
        "> Your workflow can be set to run automatically (on a regular time schedule).\n",
        "> You can also set your workflow to use a paritioning strategy such as\n",
        "> **Auto**, **Fast**, or **VLM**, instead of **High Res**.\n",
        "> [Learn how](https://docs.unstructured.io/api-reference/workflow/workflows).\n",
        ">\n",
        "---\n",
        ">\n",
        "> 💡 _When would I choose **Auto**, **Fast**, **High Res**, or **VLM**?_\n",
        ">\n",
        "> You'll learn more about these [partitioning](https://docs.unstructured.io/ui/partitioning) strategies starting with **Step 2**. But for now:\n",
        ">\n",
        "> - **Auto** is recommended in most cases. It lets Unstructured figure out the\n",
        "> best strategy to switch over to for each incoming file (and even for each\n",
        "> page if the incoming file is a PDF), so you don't have to!\n",
        "> - **Fast** is only for when you know for certain that none of your files have\n",
        "> tables, images, or multilanguage, scanned, or handwritten content in them.\n",
        "> It's optimized for partitioning text-only content and is the fastest of all\n",
        "> the strategies. It can recognize the text for only a few languages other than\n",
        "> English.\n",
        "> - **High Res** is only for when you know for certain that at least one of your\n",
        "> files has images or simple tables in them, and that none of your files also\n",
        "> have scanned or handwritten content in them. It can recognize the text for\n",
        "> more languages than **Fast** but not as many as **VLM**.\n",
        "> - **VLM** is great for any file, but it is best when you know for certain that\n",
        "> some of your files have a combination of tables (especially complex ones),\n",
        "> images, and multilanguage, scanned, or handwritten content. It's the highest\n",
        "> quality but slowest of all the strategies.\n",
        ">\n",
        "> In this walkthrough, you switch between **High Res** and **VLM** strategies\n",
        "> only to see how each of these strategies works with a combination of complex\n",
        "> tables, images, and multilanguage, scanned, and handwritten content. In\n",
        "> practice, for these kinds of files you would likely just want to choose\n",
        "> **Auto**.\n",
        ">\n",
        "---\n",
        ">\n",
        "> 💡 _This workflow has only a partitioner. What about enriching, chunking, and embedding?_\n",
        ">\n",
        "> Don't worrry; you will add nodes to this workflow for enriching, chunking,\n",
        "> and embedding later in this notebook.\n",
        ">\n",
        "---"
      ],
      "metadata": {
        "id": "MG01FnwY3Soh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Experiment with partitioning"
      ],
      "metadata": {
        "id": "_cW4MocjZpWb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, you use your new workflow to [partition](https://docs.unstructured.io/ui/partitioning) the sample PDF files that you downloaded earlier onto your local machine. Partitioning is the process where Unstructured identifies and extracts content from your source documents and then outputs this content as a series of contextually-rich document elements and metadata, which are well-tuned for RAG, agentic AI, and model fine-tuning. This step shows how well Unstructured's **High Res** partitioning strategy identifies and extracts content, and how well Unstructured's **VLM** partitioning strategy handles more complex content such as complex tables, multilanguage characters, and handwriting.\n"
      ],
      "metadata": {
        "id": "CIYjffYWxqV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Run the following cell, which sets the notebook's local input paths in the `/content/input` subfolder for the \"Chinese characters\" and \"Nash letters\" files that you uploaded from your local machine. This cell also sets the notebook's local output paths in the `/content/output` subfolder for Unstructured to send its processed data for you to view later."
      ],
      "metadata": {
        "id": "waSr6-D_fRZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_PATH = \"/content/input\"\n",
        "OUTPUT_PATH = \"/content/output\"\n",
        "CHINESE_CHARACTERS_FILE_NAME = \"2211.12781v1.pdf\"\n",
        "NASH_LETTERS_FILE_NAME = \"H03-Cryptosystem-proposed-by-Nash.pdf\"\n",
        "\n",
        "CHINESE_CHARACTERS_INPUT_PATH = f\"{INPUT_PATH}/{CHINESE_CHARACTERS_FILE_NAME}\"\n",
        "CHINESE_CHARACTERS_OUTPUT_PATH = f\"{OUTPUT_PATH}/{CHINESE_CHARACTERS_FILE_NAME}.json\"\n",
        "\n",
        "NASH_LETTERS_INPUT_PATH = f\"{INPUT_PATH}/{NASH_LETTERS_FILE_NAME}\"\n",
        "NASH_LETTERS_OUTPUT_PATH = f\"{OUTPUT_PATH}/{NASH_LETTERS_FILE_NAME}.json\""
      ],
      "metadata": {
        "id": "-yRSF-u3d-CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Run the following cell, which runs a job that is based on the workflow that you created in **Step 1**. This job is identified by its job ID, which is set programmatically so that you can use it in later cells as needed.\n",
        "\n",
        "   [Learn more about this code](https://docs.unstructured.io/api-reference/workflow/overview#run-a-workflow)."
      ],
      "metadata": {
        "id": "OacaFLbifWLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unstructured_client import UnstructuredClient\n",
        "from unstructured_client.models.operations import RunWorkflowRequest\n",
        "from unstructured_client.models.shared import InputFiles\n",
        "\n",
        "def run_workflow(file_path):\n",
        "    input_files = []\n",
        "\n",
        "    for filename in [\n",
        "        file_path\n",
        "    ]:\n",
        "        with open(filename, \"rb\") as f:\n",
        "            input_files.append(\n",
        "                InputFiles(\n",
        "                    content=f.read(),\n",
        "                    file_name=filename\n",
        "                )\n",
        "            )\n",
        "\n",
        "    with UnstructuredClient(api_key_auth=UNSTRUCTURED_API_KEY) as client:\n",
        "        response = client.workflows.run_workflow(\n",
        "            request={\n",
        "                \"workflow_id\": WORKFLOW_ID,\n",
        "                \"body_run_workflow\": {\n",
        "                    \"input_files\": input_files\n",
        "                }\n",
        "            }\n",
        "        )\n",
        "\n",
        "    print(f\"Job details:\\n---\\n{response.job_information.model_dump_json(indent=4)}\")\n",
        "\n",
        "    return response.job_information.id\n",
        "\n",
        "JOB_ID = run_workflow(CHINESE_CHARACTERS_INPUT_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbhiKbocfdCA",
        "outputId": "7c37d27f-0986-474b-ca5b-e28e16877060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job details:\n",
            "---\n",
            "{\n",
            "    \"created_at\": \"2025-09-30T18:05:11.129644Z\",\n",
            "    \"id\": \"c0e0299d-36ce-417e-b98b-f60d63d05eb7\",\n",
            "    \"status\": \"SCHEDULED\",\n",
            "    \"workflow_id\": \"ca99f800-8746-43e1-8f92-b6e36dbd22f8\",\n",
            "    \"workflow_name\": \"api-demo-workflow-2025-09-30-18-04-14\",\n",
            "    \"job_type\": \"ephemeral\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Run the following cell, which uses the job's ID to get the job's status. Do not proceed until the job polling is complete.\n",
        "\n",
        "   - If the job's final status is completed but with errors, or is failed, continue ahead to step 4 in this procedure to try to find out why.\n",
        "   - If the job's final status is stopped, try running the previous cell in step 2 again to produce a new job for this workflow.\n",
        "   - If the job's final status is successfully completed, skip ahead to step 5 in this procedure.\n",
        "\n",
        "   [Learn more about this code](https://docs.unstructured.io/api-reference/workflow/overview#get-processing-details-for-a-job).\n"
      ],
      "metadata": {
        "id": "hLIOx2BahELo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "from unstructured_client.models.operations import GetJobDetailsRequest\n",
        "\n",
        "def poll_job_status(job_id):\n",
        "    with UnstructuredClient(api_key_auth=UNSTRUCTURED_API_KEY) as client:\n",
        "        while True:\n",
        "            response = client.jobs.get_job_details(\n",
        "                request=GetJobDetailsRequest(\n",
        "                    job_id=job_id\n",
        "                )\n",
        "            )\n",
        "\n",
        "            job = response.job_details\n",
        "\n",
        "            if job.processing_status == \"SCHEDULED\":\n",
        "                print(\"Job is scheduled, polling again in 10 seconds...\")\n",
        "                time.sleep(10)\n",
        "            elif job.processing_status == \"IN_PROGRESS\":\n",
        "                print(\"Job is in progress, polling again in 10 seconds...\")\n",
        "                time.sleep(10)\n",
        "            elif job.processing_status == \"COMPLETED_WITH_ERRORS\":\n",
        "                print(\"Job completed but with errors. Run the next cell to find out why.\")\n",
        "                break\n",
        "            elif job.processing_status == \"STOPPED\":\n",
        "                print(\"Job was stopped. No data was generated.\")\n",
        "                break\n",
        "            elif job.processing_status == \"FAILED\":\n",
        "                print(\"Job failed. Run the next cell to find out why.\")\n",
        "                break\n",
        "            else:\n",
        "                print(f\"Job successfully completed.\")\n",
        "                break\n",
        "\n",
        "        return job\n",
        "\n",
        "job = poll_job_status(JOB_ID)\n",
        "print(f\"Job details:\\n---\\n{job.model_dump_json(indent=4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW-fysWohF02",
        "outputId": "a5375013-30c7-4197-b6d9-02e195c6bca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job successfully completed.\n",
            "Job details:\n",
            "---\n",
            "{\n",
            "    \"id\": \"c0e0299d-36ce-417e-b98b-f60d63d05eb7\",\n",
            "    \"node_stats\": [\n",
            "        {\n",
            "            \"failure\": 0,\n",
            "            \"in_progress\": 0,\n",
            "            \"ready\": 0,\n",
            "            \"success\": 1,\n",
            "            \"node_name\": \"Partitioner\",\n",
            "            \"node_subtype\": \"unstructured_api\",\n",
            "            \"node_type\": \"partition\"\n",
            "        }\n",
            "    ],\n",
            "    \"processing_status\": \"SUCCESS\",\n",
            "    \"message\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. If the job is completed but with errors, or is failed, run the following cell to try to find out why. Otherwise, skip ahead to step 5 in this procedure.\n",
        "\n",
        "   [Learn more about this code](https://docs.unstructured.io/api-reference/workflow/overview#get-failed-file-details-for-a-job)."
      ],
      "metadata": {
        "id": "o-RhsfEaxneM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unstructured_client.models.operations import GetJobFailedFilesRequest\n",
        "\n",
        "def get_failed_files_details(job_id):\n",
        "    with UnstructuredClient(api_key_auth=UNSTRUCTURED_API_KEY) as client:\n",
        "        response = client.jobs.get_job_failed_files(\n",
        "            request=GetJobFailedFilesRequest(\n",
        "                job_id=JOB_ID\n",
        "            )\n",
        "        )\n",
        "\n",
        "        info = response.job_failed_files\n",
        "\n",
        "        if info.failed_files.__len__() > 0:\n",
        "            print(f\"{info.failed_files.__len__()} failed file(s):\")\n",
        "\n",
        "            for failed_file in info.failed_files:\n",
        "                print(f\"---\")\n",
        "                print(f\"document: {failed_file.document}\")\n",
        "                print(f\"error:    {failed_file.error}\")\n",
        "        else:\n",
        "            print(f\"No failed files.\")\n",
        "\n",
        "get_failed_files_details(JOB_ID)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTJUcAq21Nsr",
        "outputId": "ec86ef55-453b-4bf4-a468-012236b2e5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No failed files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. If the job is successfully completed, run the following cell to download the data that Unstructured generated for the \"Chinese characters\" file to this notebook's local `/content/output` subfolder.\n",
        "\n",
        "   [Learn more about this code](https://docs.unstructured.io/api-reference/workflow/overview#download-a-processed-local-file-from-a-job)."
      ],
      "metadata": {
        "id": "At91IwoI1PU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from unstructured_client.models.operations import (\n",
        "    GetJobRequest,\n",
        "    DownloadJobOutputRequest\n",
        ")\n",
        "\n",
        "def get_job_download_details(job_id):\n",
        "    with UnstructuredClient(api_key_auth=UNSTRUCTURED_API_KEY) as client:\n",
        "        response = client.jobs.get_job(\n",
        "            request=GetJobRequest(\n",
        "                job_id=job_id\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return response.job_information\n",
        "\n",
        "def download_processed_file(job_id, file_id, node_id, output_path):\n",
        "    with UnstructuredClient(api_key_auth=UNSTRUCTURED_API_KEY) as client:\n",
        "        response = client.jobs.download_job_output(\n",
        "            request=DownloadJobOutputRequest(\n",
        "                job_id=job_id,\n",
        "                file_id=file_id,\n",
        "                node_id=node_id\n",
        "            )\n",
        "        )\n",
        "\n",
        "        with open(output_path, \"w\") as f:\n",
        "            json.dump(response.any, f, indent=4)\n",
        "\n",
        "job_info = get_job_download_details(JOB_ID)\n",
        "\n",
        "download_processed_file(\n",
        "    job_id=JOB_ID,\n",
        "    file_id=job_info.output_node_files[0].file_id,\n",
        "    node_id=job_info.output_node_files[0].node_id,\n",
        "    output_path=CHINESE_CHARACTERS_OUTPUT_PATH\n",
        ")"
      ],
      "metadata": {
        "id": "RwEPYW9d1Uxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. You can now look at the data that Unstructured generated. Do this as follows:\n",
        "\n",
        "   a. On this notebook's sidebar, click the folder (**Files**) icon, if the **Files** pane is not already shown.\n",
        "\n",
        "   b. In the **Files** pane, click to expand the `output` folder.\n",
        "   \n",
        "   c. Double-click the file titled `2211.12781v1.pdf.json`.\n",
        "   \n",
        "   d. The file's contents appear in a pane on the right side of this notebook.\n",
        "\n",
        "---\n",
        ">\n",
        "> 💡 _What am I looking at in the output here?_\n",
        ">\n",
        "> - Unstructured outputs its results in industry-standard [JSON](https://www.json.org/) format, which is\n",
        "> ideal for RAG, agentic AI, and model fine-tuning.\n",
        "> - Each object in the JSON is called a [document element](https://docs.unstructured.io/ui/document-elements) and contains a `text`\n",
        "> representation of the content that Unstructured detected for the particular\n",
        "> portion of the document that was analyzed.\n",
        "> - The `type` is the kind of document element that Unstructured categorizes it\n",
        "> as, such as whether it is a title (`Title`), a table (`Table`), an image\n",
        "> (`Image`), a series of well-formulated sentences (`NarrativeText`), some kind\n",
        "> of free text (`UncategorizedText`), a part of a list (`ListItem`), and so on. [Learn more](https://docs.unstructured.io/ui/document-elements#element-type).\n",
        "> - The `element_id` is a unique identifier that Unstructured generates to\n",
        "> refer to each document element. [Learn more](https://docs.unstructured.io/ui/document-elements#element-id).\n",
        "> - `metadata` contains supporting details about each document element, such as\n",
        "> the page number it occurred on, the file it occurred in, and so on. [Learn more](https://docs.unstructured.io/ui/document-elements#metadata).\n",
        ">\n",
        "---\n",
        "\n",
        "7. Some interesting portions of the output include the following. To search for text in the output, right-click anywhere inside the output pane, click **Command Palette**, click **Find**, and then enter the text you want to search for:\n",
        "\n",
        "   - The Chinese characters on page 3. Search for the text `In StrokeNet, the corresponding`. Notice that the Chinese characters are not interpreted correctly.\n",
        "   - The formula on page 5. Search for the text `L= LL + Ln`. Notice that the formula's output diverges quite a bit from the original content.\n",
        "   - Table 2 on page 6. Search for the text `Model Parameters Performance (BLEU)`. Notice that the `text_as_html` output diverges slightly from the original content.\n",
        "   - Figure 4 on page 8. Search for the text `50 45 40 35`. Notice that the output is not that informative about the original image's content.\n",
        "\n",
        "8. Now try changing the partitioning strategy to **VLM** and see how the output changes. To do this, run the following cell, which changes the existing workflow's partitioner node to use **VLM** partitioning instead of **High Res**.\n",
        "\n",
        "   [Learn more about this code](https://docs.unstructured.io/api-reference/workflow/overview#update-a-workflow).\n",
        "\n",
        "---\n",
        ">\n",
        "> 💡 _When would I specify a particular vision language model here? When would I choose one of these models over another?_\n",
        ">\n",
        "> A _vision language model_ (VLM) is designed to use sophisticated AI\n",
        "> techniques and logic to combine advanced image and text understanding,\n",
        "> resulting in more accurate and contextually-rich output.\n",
        ">\n",
        "> The following code uses a default VLM. As VLMs are constantly being released\n",
        "> and improved, Unstructured is always\n",
        "> adding to and updating its list of supported VLMs. If you aren't getting\n",
        "> consistent results with one VLM for a particular set of files, switching over\n",
        "> to another one might improve your results, depending on that VLM's\n",
        "> capabilities and the sample data that is was trained on."
      ],
      "metadata": {
        "id": "U4Fr2rmK1kM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unstructured_client import UnstructuredClient\n",
        "from unstructured_client.models.shared import (\n",
        "    WorkflowNode,\n",
        "    UpdateWorkflow,\n",
        "    WorkflowType\n",
        ")\n",
        "from unstructured_client.models.operations import UpdateWorkflowRequest\n",
        "\n",
        "def update_workflow_partitioner_type(WORKFLOW_ID, type):\n",
        "    with UnstructuredClient(api_key_auth=UNSTRUCTURED_API_KEY) as client:\n",
        "        partition_node = None\n",
        "\n",
        "        if type == \"vlm\":\n",
        "            partition_node = WorkflowNode(\n",
        "                name=\"Partitioner\",\n",
        "                subtype=\"vlm\",\n",
        "                type=\"partition\",\n",
        "                settings={\n",
        "                    \"is_dynamic\": \"false\",\n",
        "                    \"allow_fast\": True\n",
        "                }\n",
        "            )\n",
        "        elif type == \"hi_res\":\n",
        "            partition_node = WorkflowNode(\n",
        "                name=\"Partitioner\",\n",
        "                subtype=\"unstructured_api\",\n",
        "                type=\"partition\",\n",
        "                settings={\n",
        "                    \"strategy\": \"hi_res\"\n",
        "                }\n",
        "            )\n",
        "        else:\n",
        "            print(f\"ERROR: Cannot change workflow: Unrecognized partitioner type '{type}'.\")\n",
        "            return\n",
        "\n",
        "        workflow = UpdateWorkflow(\n",
        "            workflow_type=WorkflowType.CUSTOM,\n",
        "            workflow_nodes=[\n",
        "                partition_node\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        response = client.workflows.update_workflow(\n",
        "            request=UpdateWorkflowRequest(\n",
        "                workflow_id=WORKFLOW_ID,\n",
        "                update_workflow=workflow\n",
        "            )\n",
        "        )\n",
        "\n",
        "        print(f\"Workflow details:\\n---\\n{response.workflow_information.model_dump_json(indent=4)}\")\n",
        "\n",
        "update_workflow_partitioner_type(WORKFLOW_ID, \"vlm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3swugxcax93",
        "outputId": "b9db64ca-4063-487e-f743-886102e753c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workflow details:\n",
            "---\n",
            "{\n",
            "    \"created_at\": \"2025-09-30T18:04:14.558164Z\",\n",
            "    \"destinations\": [],\n",
            "    \"id\": \"ca99f800-8746-43e1-8f92-b6e36dbd22f8\",\n",
            "    \"name\": \"api-demo-workflow-2025-09-30-18-04-14\",\n",
            "    \"sources\": [],\n",
            "    \"status\": \"active\",\n",
            "    \"workflow_nodes\": [\n",
            "        {\n",
            "            \"name\": \"Partitioner\",\n",
            "            \"subtype\": \"vlm\",\n",
            "            \"type\": \"partition\",\n",
            "            \"id\": \"bb1600ad-1350-4ec2-8908-81ff66c50749\",\n",
            "            \"settings\": {\n",
            "                \"provider\": \"anthropic\",\n",
            "                \"provider_api_key\": null,\n",
            "                \"model\": \"claude-3-5-sonnet-20241022\",\n",
            "                \"output_format\": \"text/html\",\n",
            "                \"prompt\": null,\n",
            "                \"format_html\": true,\n",
            "                \"unique_element_ids\": true,\n",
            "                \"is_dynamic\": false,\n",
            "                \"allow_fast\": true,\n",
            "                \"custom_host_config\": null\n",
            "            }\n",
            "        }\n",
            "    ],\n",
            "    \"reprocess_all\": true,\n",
            "    \"schedule\": {\n",
            "        \"crontab_entries\": []\n",
            "    },\n",
            "    \"updated_at\": \"2025-09-30T18:07:41.455845Z\",\n",
            "    \"workflow_type\": \"custom\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Run the following cell, which runs the workflow as a job and returns the job's ID."
      ],
      "metadata": {
        "id": "pb8ZM0DLcjQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "JOB_ID = run_workflow(CHINESE_CHARACTERS_INPUT_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0p1-Pohcrj7",
        "outputId": "9d0e854e-54a2-4e0d-a00e-a8dd4f56135b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job details:\n",
            "---\n",
            "{\n",
            "    \"created_at\": \"2025-09-30T18:07:53.122512Z\",\n",
            "    \"id\": \"296f04ae-47be-4f6a-8aee-db5dc02648b1\",\n",
            "    \"status\": \"SCHEDULED\",\n",
            "    \"workflow_id\": \"ca99f800-8746-43e1-8f92-b6e36dbd22f8\",\n",
            "    \"workflow_name\": \"api-demo-workflow-2025-09-30-18-04-14\",\n",
            "    \"job_type\": \"ephemeral\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Run the following cell, which keeps polling for job status until the job is finished."
      ],
      "metadata": {
        "id": "WO8YjE1tcs9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = poll_job_status(JOB_ID)\n",
        "print(f\"Job details:\\n---\\n{job.model_dump_json(indent=4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBHeZhfEc2D_",
        "outputId": "1e34b5d1-5411-4489-d8ac-77e971dda6d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job successfully completed.\n",
            "Job details:\n",
            "---\n",
            "{\n",
            "    \"id\": \"296f04ae-47be-4f6a-8aee-db5dc02648b1\",\n",
            "    \"node_stats\": [\n",
            "        {\n",
            "            \"failure\": 0,\n",
            "            \"in_progress\": 1,\n",
            "            \"ready\": 0,\n",
            "            \"success\": 0,\n",
            "            \"node_name\": \"Partitioner\",\n",
            "            \"node_subtype\": \"vlm\",\n",
            "            \"node_type\": \"partition\"\n",
            "        }\n",
            "    ],\n",
            "    \"processing_status\": \"SUCCESS\",\n",
            "    \"message\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. After the job finishes successfully, run the following cell, which downloads Unstructured's output to the notebook's local `/content/output` subfolder."
      ],
      "metadata": {
        "id": "HVxF9A7BdGCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_info = get_job_download_details(JOB_ID)\n",
        "\n",
        "download_processed_file(\n",
        "    job_id=JOB_ID,\n",
        "    file_id=job_info.output_node_files[0].file_id,\n",
        "    node_id=job_info.output_node_files[0].node_id,\n",
        "    output_path=CHINESE_CHARACTERS_OUTPUT_PATH\n",
        ")"
      ],
      "metadata": {
        "id": "KYmdoVxAdHl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Open the new version of this \"Chinese characters\" output file (if the version from the previous steps is already open, close it, and then open this new version instead) and notice how the quality of the output changes, now that you are using the **VLM** strategy:\n",
        "\n",
        "    - The Chinese characters on page 3. Search for the text `In StrokeNet, the corresponding`. Notice that the Chinese characters are intepreted correctly.\n",
        "    - The formula on page 5. Search for the text `match class`. Notice that the formula's output is closer to the original content.\n",
        "    - Table 2 on page 6. Search for the text `Model Parameters Performance (BLEU)`. Notice that the text_as_html output is closer to the original content.\n",
        "    - Figure 4 on page 8. Search for the text `Graph showing BLEU scores comparison`. Notice the informative description about the figure.\n",
        "\n",
        "13. Now try looking at the \"Nash letters\" PDF file's output by having Unstructured use the **High Res** partitioning strategy. To do this, run the following cell, which changes the existing workflow's partitioner node back to use **High Res** partitioning instead of **VLM**."
      ],
      "metadata": {
        "id": "a6pwhkCLdhou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "update_workflow_partitioner_type(WORKFLOW_ID, \"hi_res\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veqoDQ3cnAYu",
        "outputId": "4c8fba29-cfd6-44b7-f399-04b2f726d4fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workflow details:\n",
            "---\n",
            "{\n",
            "    \"created_at\": \"2025-09-30T18:04:14.558164Z\",\n",
            "    \"destinations\": [],\n",
            "    \"id\": \"ca99f800-8746-43e1-8f92-b6e36dbd22f8\",\n",
            "    \"name\": \"api-demo-workflow-2025-09-30-18-04-14\",\n",
            "    \"sources\": [],\n",
            "    \"status\": \"active\",\n",
            "    \"workflow_nodes\": [\n",
            "        {\n",
            "            \"name\": \"Partitioner\",\n",
            "            \"subtype\": \"unstructured_api\",\n",
            "            \"type\": \"partition\",\n",
            "            \"id\": \"ab79abf8-a911-47a5-97c4-40ce00dad93b\",\n",
            "            \"settings\": {\n",
            "                \"strategy\": \"hi_res\",\n",
            "                \"include_page_breaks\": false,\n",
            "                \"pdf_infer_table_structure\": false,\n",
            "                \"exclude_elements\": null,\n",
            "                \"xml_keep_tags\": false,\n",
            "                \"encoding\": \"utf-8\",\n",
            "                \"extract_image_block_types\": [\n",
            "                    \"image\",\n",
            "                    \"table\"\n",
            "                ]\n",
            "            }\n",
            "        }\n",
            "    ],\n",
            "    \"reprocess_all\": true,\n",
            "    \"schedule\": {\n",
            "        \"crontab_entries\": []\n",
            "    },\n",
            "    \"updated_at\": \"2025-09-30T18:15:58.658448Z\",\n",
            "    \"workflow_type\": \"custom\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Run the following cell, which runs the workflow as a job and returns the job's ID."
      ],
      "metadata": {
        "id": "qZ3uGbw_nB9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "JOB_ID = run_workflow(NASH_LETTERS_INPUT_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GZnTarJlFPC",
        "outputId": "ef5ecaf4-df42-403a-d79e-161609308129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job details:\n",
            "---\n",
            "{\n",
            "    \"created_at\": \"2025-09-30T18:16:03.822526Z\",\n",
            "    \"id\": \"807838fd-b3ea-494c-8ae8-5a155ac8cab4\",\n",
            "    \"status\": \"SCHEDULED\",\n",
            "    \"workflow_id\": \"ca99f800-8746-43e1-8f92-b6e36dbd22f8\",\n",
            "    \"workflow_name\": \"api-demo-workflow-2025-09-30-18-04-14\",\n",
            "    \"job_type\": \"ephemeral\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Run the following cell, which keeps polling for job status until the job is finished."
      ],
      "metadata": {
        "id": "enLxTpc0lJ7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = poll_job_status(JOB_ID)\n",
        "print(f\"Job details:\\n---\\n{job.model_dump_json(indent=4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edFBrghvlM6g",
        "outputId": "ec54c1ba-397f-49bb-975e-ff4dc9154f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job successfully completed.\n",
            "Job details:\n",
            "---\n",
            "{\n",
            "    \"id\": \"807838fd-b3ea-494c-8ae8-5a155ac8cab4\",\n",
            "    \"node_stats\": [\n",
            "        {\n",
            "            \"failure\": 0,\n",
            "            \"in_progress\": 0,\n",
            "            \"ready\": 0,\n",
            "            \"success\": 1,\n",
            "            \"node_name\": \"Partitioner\",\n",
            "            \"node_subtype\": \"unstructured_api\",\n",
            "            \"node_type\": \"partition\"\n",
            "        }\n",
            "    ],\n",
            "    \"processing_status\": \"SUCCESS\",\n",
            "    \"message\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. After the job finishes successfully, run the following cell, which downloads Unstructured's output to the notebook's local `/content/output` subfolder."
      ],
      "metadata": {
        "id": "FWRPCcsGlQaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_info = get_job_download_details(JOB_ID)\n",
        "\n",
        "download_processed_file(\n",
        "    job_id=JOB_ID,\n",
        "    file_id=job_info.output_node_files[0].file_id,\n",
        "    node_id=job_info.output_node_files[0].node_id,\n",
        "    output_path=NASH_LETTERS_OUTPUT_PATH\n",
        ")"
      ],
      "metadata": {
        "id": "3--_mWydlSNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Some interesting portions of the **High Res** output for the `H03-Cryptosystem-proposed-by-Nash.pdf.json` file against the original handwritten and scanned content include the following. Remember, to search for text in the output, right-click anywhere inside the output pane, click **Command Palette**, click **Find**, and then enter the text you want to search for:\n",
        "\n",
        "    - The handwriting on page 3. Search for the text `Deo Majr`. Notice that the handwriting is not recognized correctly.\n",
        "    - The mimeograph on page 11. Search for the text `Technicans at this Agency` (note the typo `Technicans`). Notice that the mimeograph contains `18 January 1955`, but the output contains only `January 1955`.\n",
        "    - The handwritten diagrams on page 13. Search for the text `\"page_number\": 13`. Notice that no output is generated for the diagrams.\n",
        "\n",
        "18. Now try changing the partitioning strategy to **VLM** and see how the quality of the output changes. To do this, run the following cell, which changes the existing workflow's partitioner node to use **VLM** partitioning instead of **High Res**."
      ],
      "metadata": {
        "id": "lvv6v8D9nd1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "update_workflow_partitioner_type(WORKFLOW_ID, \"vlm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4WwlhQun9vO",
        "outputId": "9ab9c585-4db8-4f9d-cc52-de4462d59ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workflow details:\n",
            "---\n",
            "{\n",
            "    \"created_at\": \"2025-09-30T18:04:14.558164Z\",\n",
            "    \"destinations\": [],\n",
            "    \"id\": \"ca99f800-8746-43e1-8f92-b6e36dbd22f8\",\n",
            "    \"name\": \"api-demo-workflow-2025-09-30-18-04-14\",\n",
            "    \"sources\": [],\n",
            "    \"status\": \"active\",\n",
            "    \"workflow_nodes\": [\n",
            "        {\n",
            "            \"name\": \"Partitioner\",\n",
            "            \"subtype\": \"vlm\",\n",
            "            \"type\": \"partition\",\n",
            "            \"id\": \"4396a0fb-a85f-4a5c-8b89-c7198aa6a19b\",\n",
            "            \"settings\": {\n",
            "                \"provider\": \"anthropic\",\n",
            "                \"provider_api_key\": null,\n",
            "                \"model\": \"claude-3-5-sonnet-20241022\",\n",
            "                \"output_format\": \"text/html\",\n",
            "                \"prompt\": null,\n",
            "                \"format_html\": true,\n",
            "                \"unique_element_ids\": true,\n",
            "                \"is_dynamic\": false,\n",
            "                \"allow_fast\": true,\n",
            "                \"custom_host_config\": null\n",
            "            }\n",
            "        }\n",
            "    ],\n",
            "    \"reprocess_all\": true,\n",
            "    \"schedule\": {\n",
            "        \"crontab_entries\": []\n",
            "    },\n",
            "    \"updated_at\": \"2025-09-30T18:25:17.584361Z\",\n",
            "    \"workflow_type\": \"custom\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Run the following cell, which runs the workflow as a job and returns the job's ID.\n",
        "\n"
      ],
      "metadata": {
        "id": "Rljc9t-GoCxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "JOB_ID = run_workflow(NASH_LETTERS_INPUT_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOXuJHd8oHkx",
        "outputId": "cbdebb14-8c74-4998-f92f-6975a3ade0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job details:\n",
            "---\n",
            "{\n",
            "    \"created_at\": \"2025-09-30T18:25:21.531927Z\",\n",
            "    \"id\": \"95c0c04a-0ad0-4f59-8e1c-4c3b1330cce2\",\n",
            "    \"status\": \"SCHEDULED\",\n",
            "    \"workflow_id\": \"ca99f800-8746-43e1-8f92-b6e36dbd22f8\",\n",
            "    \"workflow_name\": \"api-demo-workflow-2025-09-30-18-04-14\",\n",
            "    \"job_type\": \"ephemeral\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Run the following cell, which keeps polling for job status until the job is finished.\n",
        "\n"
      ],
      "metadata": {
        "id": "gRgP0R5-oLcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = poll_job_status(JOB_ID)\n",
        "print(f\"Job details:\\n---\\n{job.model_dump_json(indent=4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWAFbEHgoPmj",
        "outputId": "0d2361e8-351c-4a1b-f353-0bf205f90db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job is in progress, polling again in 10 seconds...\n",
            "Job successfully completed.\n",
            "Job details:\n",
            "---\n",
            "{\n",
            "    \"id\": \"95c0c04a-0ad0-4f59-8e1c-4c3b1330cce2\",\n",
            "    \"node_stats\": [\n",
            "        {\n",
            "            \"failure\": 0,\n",
            "            \"in_progress\": 0,\n",
            "            \"ready\": 0,\n",
            "            \"success\": 1,\n",
            "            \"node_name\": \"Partitioner\",\n",
            "            \"node_subtype\": \"vlm\",\n",
            "            \"node_type\": \"partition\"\n",
            "        }\n",
            "    ],\n",
            "    \"processing_status\": \"SUCCESS\",\n",
            "    \"message\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. After the job finishes successfully, run the following cell, which downloads Unstructured's output to the notebook's local `/content/output` subfolder."
      ],
      "metadata": {
        "id": "KGVPHGHnoTxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_info = get_job_download_details(JOB_ID)\n",
        "\n",
        "download_processed_file(\n",
        "    job_id=JOB_ID,\n",
        "    file_id=job_info.output_node_files[0].file_id,\n",
        "    node_id=job_info.output_node_files[0].node_id,\n",
        "    output_path=NASH_LETTERS_OUTPUT_PATH\n",
        ")"
      ],
      "metadata": {
        "id": "0GSnZaKNoa7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Open the new version of this \"Nash letters\" output file (if the version from the previous steps is already open, close it, and then open this new version instead). Notice how the output changes, now that you are using the **VLM** strategy:\n",
        "\n",
        "    - The handwriting on page 3. Search for the text `Dear Major Grosjean`. Notice how well the handwriting is recognized correctly.\n",
        "    - The mimeograph on page 11. Search for the text `Technicians at this Agency` (note the corrected typo `Technicians`). Notice that the mimoegraph contains `18 January 1955`, and the output now also contains `18 January 1955`.\n",
        "    - The handwritten diagrams on page 13. Search for the text `graph LR`. Notice that Mermaid representations of the handwritten diagrams are output."
      ],
      "metadata": {
        "id": "W7W2szCHoeBo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Experiment with enriching"
      ],
      "metadata": {
        "id": "5r7WXi6Mo1Uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, you add several [enrichments](https://docs.unstructured.io/ui/enriching/overview) to your workflow, such as generating summary descriptions of detected images and tables, HTML representations of detected tables, and detected entities (such as people and organizations) and the inferred relationships among these entities.\n",
        "\n",
        "---\n",
        ">\n",
        "> 💡 _Can you tell me more about what each of these enrichments actually do?_\n",
        ">\n",
        "> The _image description_ enrichment generates a summary description of each\n",
        "> detected image. This can help you to more quickly and easily understand what\n",
        "> each image is all about without having to stop to manually visualize and\n",
        "> interpret the image's content yourself. This also provides additional helpful\n",
        "> context about the image for your RAG apps, agents, and models.\n",
        "> [Learn more](https://docs.unstructured.io/ui/enriching/image-descriptions).\n",
        ">\n",
        "> The _table description_ enrichment generates a summary description of each\n",
        "> detected table. This can help you to more quickly and easily understand what\n",
        "> each table is all about without having to stop to manually read through the\n",
        "> table's content yourself. This also provides additional helpful context about\n",
        "> the table for your RAG apps, agents, and models.\n",
        "> [Learn more](https://docs.unstructured.io/ui/enriching/table-descriptions).\n",
        ">\n",
        "> The _table-to-HTML_ enrichment generates an HTML representation of each\n",
        "> detected table. This can help you to more quickly and accurately recreate the\n",
        "> table's content elsewhere later as needed. This also provides additional\n",
        "> context about the table's structure for your RAG apps, agents, and models.\n",
        "> [Learn more](https://docs.unstructured.io/ui/enriching/table-to-html).\n",
        ">\n",
        "> The _named entity recognition (NER)_ enrichment generates a list of detected\n",
        "> entities (such as people and organizations) and the inferred relationships\n",
        "> among these entities. This provides additional context about these entities'\n",
        "> types and their relationships for your graph databases, RAG apps, agents, and\n",
        "> models.\n",
        "> [Learn more](https://docs.unstructured.io/ui/enriching/ner).\n",
        ">\n",
        "---\n",
        "\n",
        "1. Run the following cell, which changes the existing workflow to use **High Res** partitioning and also adds workflow nodes for generating the image and table summary descriptions, table HTML, and entities and their relationships.\n",
        "\n",
        "   [Learn more about this code](https://docs.unstructured.io/api-reference/workflow/workflows#enrichment-node)."
      ],
      "metadata": {
        "id": "Gb-337y2X-k8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unstructured_client import UnstructuredClient\n",
        "from unstructured_client.models.shared import (\n",
        "    WorkflowNode,\n",
        "    UpdateWorkflow,\n",
        "    WorkflowType\n",
        ")\n",
        "from unstructured_client.models.operations import UpdateWorkflowRequest\n",
        "\n",
        "with UnstructuredClient(api_key_auth=UNSTRUCTURED_API_KEY) as client:\n",
        "    partition_node = WorkflowNode(\n",
        "        name=\"Partitioner\",\n",
        "        subtype=\"unstructured_api\",\n",
        "        type=\"partition\",\n",
        "        settings={\n",
        "            \"strategy\": \"hi_res\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    image_description_enrichment_node = WorkflowNode(\n",
        "        name=\"OpenAI Image Description\",\n",
        "        subtype=\"openai_image_description\",\n",
        "        type=\"prompter\",\n",
        "        settings={}\n",
        "    )\n",
        "\n",
        "    table_description_enrichment_node = WorkflowNode(\n",
        "        name=\"OpenAI Table Description\",\n",
        "        subtype=\"openai_table_description\",\n",
        "        type=\"prompter\",\n",
        "        settings={}\n",
        "    )\n",
        "\n",
        "    table_to_html_enrichment_node = WorkflowNode(\n",
        "        name=\"OpenAI Table to HTML\",\n",
        "        subtype=\"openai_table2html\",\n",
        "        type=\"prompter\",\n",
        "        settings={}\n",
        "    )\n",
        "\n",
        "    named_entity_recognition_enrichment_node = WorkflowNode(\n",
        "        name=\"OpenAI NER\",\n",
        "        subtype=\"openai_ner\",\n",
        "        type=\"prompter\",\n",
        "        settings={}\n",
        "    )\n",
        "\n",
        "    workflow = UpdateWorkflow(\n",
        "        workflow_type=WorkflowType.CUSTOM,\n",
        "        workflow_nodes=[\n",
        "            partition_node,\n",
        "            image_description_enrichment_node,\n",
        "            table_description_enrichment_node,\n",
        "            table_to_html_enrichment_node,\n",
        "            named_entity_recognition_enrichment_node\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    response = client.workflows.update_workflow(\n",
        "        request=UpdateWorkflowRequest(\n",
        "            workflow_id=WORKFLOW_ID,\n",
        "            update_workflow=workflow\n",
        "        )\n",
        "    )\n",
        "\n",
        "    print(f\"Workflow details:\\n---\\n{response.workflow_information.model_dump_json(indent=4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OnH5g6QZtR6",
        "outputId": "b753f57d-821e-4ba6-9d2f-3407aded2cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workflow details:\n",
            "---\n",
            "{\n",
            "    \"created_at\": \"2025-09-30T18:04:14.558164Z\",\n",
            "    \"destinations\": [],\n",
            "    \"id\": \"ca99f800-8746-43e1-8f92-b6e36dbd22f8\",\n",
            "    \"name\": \"api-demo-workflow-2025-09-30-18-04-14\",\n",
            "    \"sources\": [],\n",
            "    \"status\": \"active\",\n",
            "    \"workflow_nodes\": [\n",
            "        {\n",
            "            \"name\": \"OpenAI NER\",\n",
            "            \"subtype\": \"openai_ner\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"e80b0e6b-cac5-4425-ae53-d97957eb7468\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"OpenAI Table to HTML\",\n",
            "            \"subtype\": \"openai_table2html\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"62d77501-3077-4b0f-a82e-9da8904a5c0e\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"OpenAI Table Description\",\n",
            "            \"subtype\": \"openai_table_description\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"6ef107c9-77dd-4561-90b0-5d9dd5920621\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"Partitioner\",\n",
            "            \"subtype\": \"unstructured_api\",\n",
            "            \"type\": \"partition\",\n",
            "            \"id\": \"ca01f853-89b5-456c-be0e-bc188572b133\",\n",
            "            \"settings\": {\n",
            "                \"strategy\": \"hi_res\",\n",
            "                \"include_page_breaks\": false,\n",
            "                \"pdf_infer_table_structure\": false,\n",
            "                \"exclude_elements\": null,\n",
            "                \"xml_keep_tags\": false,\n",
            "                \"encoding\": \"utf-8\",\n",
            "                \"extract_image_block_types\": [\n",
            "                    \"image\",\n",
            "                    \"table\"\n",
            "                ]\n",
            "            }\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"OpenAI Image Description\",\n",
            "            \"subtype\": \"openai_image_description\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"8921f656-a7fe-464f-9041-baa89f85cdce\",\n",
            "            \"settings\": {}\n",
            "        }\n",
            "    ],\n",
            "    \"reprocess_all\": true,\n",
            "    \"schedule\": {\n",
            "        \"crontab_entries\": []\n",
            "    },\n",
            "    \"updated_at\": \"2025-10-01T18:13:58.996193Z\",\n",
            "    \"workflow_type\": \"custom\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Run the following cell, which runs the workflow as a job and returns the job's ID."
      ],
      "metadata": {
        "id": "aP7KLPv3_J6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "JOB_ID = run_workflow(CHINESE_CHARACTERS_INPUT_PATH)"
      ],
      "metadata": {
        "id": "4bePo4Az_NGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Run the following cell, which keeps polling for job status until the job is finished."
      ],
      "metadata": {
        "id": "pB3uD0Il_bV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = poll_job_status(JOB_ID)\n",
        "print(f\"Job details:\\n---\\n{job.model_dump_json(indent=4)}\")"
      ],
      "metadata": {
        "id": "PomgNDLN_dEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. After the job finishes successfully, run the following cell, which downloads Unstructured's output to the notebook's local `/content/output` subfolder."
      ],
      "metadata": {
        "id": "Cs1KwLYs_pIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_info = get_job_download_details(JOB_ID)\n",
        "\n",
        "download_processed_file(\n",
        "    job_id=JOB_ID,\n",
        "    file_id=job_info.output_node_files[0].file_id,\n",
        "    node_id=job_info.output_node_files[0].node_id,\n",
        "    output_path=CHINESE_CHARACTERS_OUTPUT_PATH\n",
        ")"
      ],
      "metadata": {
        "id": "7sdAbMQv_sog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Open the new version of this \"Chinese characters\" output file (if the version from the previous steps is already open, close it, and then open this new version instead). Some interesting portions of the output include the following:\n",
        "\n",
        "   - The figures on pages 3, 7, and 8. Search for the seven instances of the text `\"type\": \"Image\"`. Notice the summary description for each image.\n",
        "   - The tables on pages 6, 7, 8, 9, and 12. Search for the seven instances of the text `\"type\": \"Table\"`. Notice the summary description for each of these tables. Also notice the `text_as_html` field for each of these tables.\n",
        "   - The identified entities and inferred relationships among them. Search for the text `Zhijun Wang`. Of the eight instances of this name, notice the author's identification as a `PERSON` three times, the author's `published` relationship twice, and the author's `affiliated_with` relationship twice."
      ],
      "metadata": {
        "id": "Cc9a741r_2gq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Experiment with chunking"
      ],
      "metadata": {
        "id": "DVzXu-APAvg0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, you apply [chunking](https://docs.unstructured.io/ui/chunking) to your workflow. Chunking is the process where Unstructured rearranges the resulting document elements' `text` content into manageable \"chunks\" to stay within the limits of an AI model and to improve retrieval precision.\n",
        "\n",
        "---\n",
        ">\n",
        "> 💡 _What kind of chunking strategy should I use, and how big should my chunks be?_\n",
        ">\n",
        "> Unfortunately, there is no one-size-fits-all answer to this question.\n",
        "> However, there are some general considerations and guidelines that can help\n",
        "> you to determine the best chunking strategy and chunk size for your specific\n",
        "> use case. Be sure of course to also consult the documentation for your target\n",
        "> AI model and downstream application toolsets.\n",
        ">\n",
        "> Is your content primarily organized by title, by page, by interrelated\n",
        "> subject matter, or none of these? This can help you determine whether a\n",
        "> by-title, by-page, by-similarity, or basic (by-character) chunking strategy\n",
        "> is best. (You'll experiment with each of these strategies here later.)\n",
        ">\n",
        "> If your chunks are too small, they might lose necessary context, leading to\n",
        "> the model providing inaccurate, irrelevant, or hallucinated results. On the\n",
        "> other hand, if your chunks are too large, the model can struggle with the\n",
        "> sheer volume of information, leading to information overload, diluted\n",
        "> meaning, and potentially higher processing costs. You should aim to find a\n",
        "> balance between chunks that are big enough to contain meaningful information,\n",
        "> while small enough to enable performant applications and low latency\n",
        "> responses.\n",
        ">\n",
        "> For example, smaller chunks of 128 or 256 tokens might be sufficient for\n",
        "> capturing more granular semantic information, while larger chunks of 512 or\n",
        "> 1024 tokens might be better for retaining more context. It's important here\n",
        "> to note that _tokens_ and _characters_ are not the same thing! In terms of\n",
        "> characters, for English text, a common approximation is 1 token being equal\n",
        "> to about 3 or 4 characters or three-quarters of a word. Many AI model\n",
        "> providers publish their own token-to-character calculators online that you\n",
        "> can use for estimation purposes.\n",
        ">\n",
        "> You should experiement with a variety of chunk sizes, taking into account the\n",
        "> kinds of content, the length and complexity of user queries and agent tasks,\n",
        "> the intended end use, and of course the limits of the models you are using.\n",
        "> Try different chunking strategies and sizes with your models and evaluate the\n",
        "> results for yourself.\n",
        ">\n",
        "---\n",
        "\n",
        "1. Run the following code, which changes the existing workflow to add a workflow node that chunks the document elements' `text` by using a character-based strategy.\n",
        "\n",
        "   [Learn more about this code](https://docs.unstructured.io/api-reference/workflow/workflows#chunker-node).\n",
        "\n",
        "---\n",
        ">\n",
        "> 💡 _What do each of the following chunking settings do?_\n",
        ">\n",
        "> - Contextual chunking (`contextual_chunking_strategy`) prepends\n",
        ">   chunk-specific explanatory context to each chunk, which has been shown to\n",
        ">   yield significant improvements in downstream retrieval accuracy.\n",
        ">   [Learn more]().\n",
        "> - Include original elements (`include_orig_elements`) outputs into each\n",
        ">   chunk's `metadata` field's `orig_elements` value the elements that were\n",
        ">   used to form that particular chunk.\n",
        ">   [Learn more]().\n",
        "> - Max characters (`max_characters`) is the \"hard\" or maximum number of\n",
        ">   characters that any one chunk can contain. Unstructured cannot exceed this\n",
        ">   number when forming chunks.\n",
        ">   [Learn more]().\n",
        "> - New after n characters (`new_after_n_characters`) is the \"soft\" or\n",
        ">   approximate number of characters that any one chunk can contain.\n",
        ">   Unstructured can exceed this number if needed when forming chunks (but\n",
        ">   still cannot exceed the max characters setting).\n",
        ">   [Learn more]().\n",
        "> - Overlap (`overlap`), when applied (see `overlap_all`), prepends to the\n",
        ">   current chunk the specified number of characters from the previous chunk,\n",
        ">   which can help provide additional context about this chunk relative to the\n",
        ">   previous chunk.\n",
        ">   [Learn more]().\n",
        "> - Overlap all (`overlap_all`), applies the `overlap` setting (if greater than\n",
        ">   zero) to all chunks. Otherwise, setting `overlap_all` to `False` that the\n",
        ">   `overlap` setting (if greater than zero) is applied only in edge cases\n",
        ">   where `normal` chunks cannot be formed by combining whole elements. Set\n",
        ">   `overlap_all` to `True` with caution as it can introduce noise into\n",
        ">   otherwise clean semantic units.\n",
        ">   [Learn more]().\n",
        "> - Combine text under n characters (`combine_text_under_n_characters`)\n",
        ">   combines elements from a section into a chunk until a section reaches a\n",
        ">   length of this many characters.\n",
        ">   [Learn more]().\n",
        "> - Multipage sections (`multipage_sections`), when set to `True`, allows\n",
        ">   sections to span multiple pages.\n",
        ">   [Learn more]().\n",
        "> - The similarity threshold (`similarity_threshold`) is a number between `0`\n",
        ">   and `1` exclusive (`0.01` to `0.99` inclusive). `0.01` means that any two\n",
        ">   segments of text that are being compared to each other and are considered\n",
        ">   least identical in semantic meaning to each other are more likely to be\n",
        ">   combined into the same chunk together, when such combining must occur.\n",
        ">   `0.99` means that any two segments of text that are being compared to each\n",
        ">   other and are considered almost identical in semantic meaning to each other\n",
        ">   are more likely to be combined into the same chunk together, when such\n",
        ">   combining must occur. Numbers toward `0.01` bias toward least-identical\n",
        ">   semantic matches, while numbers toward `0.99` bias toward near-identical\n",
        ">   semantic matches.\n",
        ">   [Learn more]()."
      ],
      "metadata": {
        "id": "85MBTZo5AyuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unstructured_client import UnstructuredClient\n",
        "from unstructured_client.models.shared import (\n",
        "    WorkflowNode,\n",
        "    UpdateWorkflow,\n",
        "    WorkflowType\n",
        ")\n",
        "from unstructured_client.models.operations import UpdateWorkflowRequest\n",
        "\n",
        "def update_workflow_chunker_type(\n",
        "    workflow_id=None,\n",
        "    subtype=None,\n",
        "    max_characters=None,\n",
        "    new_after_n_characters=None,\n",
        "    combine_text_under_n_chars=None,\n",
        "    overlap=None,\n",
        "    overlap_all=False,\n",
        "    multipage_sections=False,\n",
        "    include_orig_elements=False,\n",
        "    contextual_chunking_strategy=None,\n",
        "    similarity_threshold=None\n",
        "):\n",
        "    with UnstructuredClient(api_key_auth=UNSTRUCTURED_API_KEY) as client:\n",
        "        partition_node = WorkflowNode(\n",
        "            name=\"Partitioner\",\n",
        "            subtype=\"unstructured_api\",\n",
        "            type=\"partition\",\n",
        "            settings={\n",
        "                \"strategy\": \"hi_res\"\n",
        "            }\n",
        "        )\n",
        "\n",
        "        image_description_enrichment_node = WorkflowNode(\n",
        "            name=\"OpenAI Image Description\",\n",
        "            subtype=\"openai_image_description\",\n",
        "            type=\"prompter\",\n",
        "            settings={}\n",
        "        )\n",
        "\n",
        "        table_description_enrichment_node = WorkflowNode(\n",
        "            name=\"OpenAI Table Description\",\n",
        "            subtype=\"openai_table_description\",\n",
        "            type=\"prompter\",\n",
        "            settings={}\n",
        "        )\n",
        "\n",
        "        table_to_html_enrichment_node = WorkflowNode(\n",
        "            name=\"OpenAI Table to HTML\",\n",
        "            subtype=\"openai_table2html\",\n",
        "            type=\"prompter\",\n",
        "            settings={}\n",
        "        )\n",
        "\n",
        "        named_entity_recognition_enrichment_node = WorkflowNode(\n",
        "            name=\"OpenAI NER\",\n",
        "            subtype=\"openai_ner\",\n",
        "            type=\"prompter\",\n",
        "            settings={}\n",
        "        )\n",
        "\n",
        "        chunker_node = None\n",
        "\n",
        "        if subtype == \"chunk_by_character\":\n",
        "            chunker_node = WorkflowNode(\n",
        "                name=\"Chunker\",\n",
        "                subtype=subtype,\n",
        "                type=\"chunk\",\n",
        "                settings={\n",
        "                    \"include_orig_elements\": include_orig_elements,\n",
        "                    \"new_after_n_chars\": new_after_n_characters,\n",
        "                    \"max_characters\": max_characters,\n",
        "                    \"overlap\": overlap,\n",
        "                    \"overlap_all\": overlap_all,\n",
        "                    \"contextual_chunking_strategy\": contextual_chunking_strategy\n",
        "                }\n",
        "            )\n",
        "        elif subtype == \"chunk_by_title\":\n",
        "            chunker_node = WorkflowNode(\n",
        "                name=\"Chunker\",\n",
        "                subtype=subtype,\n",
        "                type=\"chunk\",\n",
        "                settings={\n",
        "                    \"multipage_sections\": multipage_sections,\n",
        "                    \"combine_text_under_n_chars\": combine_text_under_n_chars,\n",
        "                    \"include_orig_elements\": include_orig_elements,\n",
        "                    \"new_after_n_chars\": new_after_n_characters,\n",
        "                    \"max_characters\": max_characters,\n",
        "                    \"overlap\": overlap,\n",
        "                    \"overlap_all\": overlap_all,\n",
        "                    \"contextual_chunking_strategy\": contextual_chunking_strategy\n",
        "                }\n",
        "            )\n",
        "        elif subtype == \"chunk_by_page\":\n",
        "            chunker_node = WorkflowNode(\n",
        "                name=\"Chunker\",\n",
        "                subtype=\"chunk_by_page\",\n",
        "                type=\"chunk\",\n",
        "                settings={\n",
        "                    \"include_orig_elements\": include_orig_elements,\n",
        "                    \"new_after_n_chars\": new_after_n_characters,\n",
        "                    \"max_characters\": max_characters,\n",
        "                    \"overlap\": overlap,\n",
        "                    \"overlap_all\": overlap_all,\n",
        "                    \"contextual_chunking_strategy\": contextual_chunking_strategy\n",
        "                }\n",
        "            )\n",
        "        elif subtype == \"chunk_by_similarity\":\n",
        "            chunker_node = WorkflowNode(\n",
        "              name=\"Chunker\",\n",
        "              subtype=\"chunk_by_similarity\",\n",
        "              type=\"chunk\",\n",
        "              settings={\n",
        "                  \"include_orig_elements\": include_orig_elements,\n",
        "                  \"new_after_n_chars\": new_after_n_characters,\n",
        "                  \"max_characters\": max_characters,\n",
        "                  \"overlap\": overlap,\n",
        "                  \"overlap_all\": overlap_all,\n",
        "                  \"contextual_chunking_strategy\": contextual_chunking_strategy,\n",
        "                  \"similarity_threshold\": similarity_threshold\n",
        "              }\n",
        "            )\n",
        "        else:\n",
        "            print(f\"ERROR: Cannot change workflow: Unrecognized chunker subtype '{subtype}'.\")\n",
        "            return\n",
        "\n",
        "        workflow = UpdateWorkflow(\n",
        "            workflow_type=WorkflowType.CUSTOM,\n",
        "            workflow_nodes=[\n",
        "                partition_node,\n",
        "                image_description_enrichment_node,\n",
        "                table_description_enrichment_node,\n",
        "                table_to_html_enrichment_node,\n",
        "                named_entity_recognition_enrichment_node,\n",
        "                chunker_node\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        response = client.workflows.update_workflow(\n",
        "            request=UpdateWorkflowRequest(\n",
        "                workflow_id=WORKFLOW_ID,\n",
        "                update_workflow=workflow\n",
        "            )\n",
        "        )\n",
        "\n",
        "        print(f\"Workflow details:\\n---\\n{response.workflow_information.model_dump_json(indent=4)}\")\n",
        "\n",
        "update_workflow_chunker_type(\n",
        "    subtype=\"chunk_by_character\",\n",
        "    max_characters=500,\n",
        "    new_after_n_characters=400,\n",
        "    overlap=50,\n",
        "    include_orig_elements=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXWu39uICPsm",
        "outputId": "720aec86-a4e4-44b7-f053-9dbe08ead43c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workflow details:\n",
            "---\n",
            "{\n",
            "    \"created_at\": \"2025-09-30T18:04:14.558164Z\",\n",
            "    \"destinations\": [],\n",
            "    \"id\": \"ca99f800-8746-43e1-8f92-b6e36dbd22f8\",\n",
            "    \"name\": \"api-demo-workflow-2025-09-30-18-04-14\",\n",
            "    \"sources\": [],\n",
            "    \"status\": \"active\",\n",
            "    \"workflow_nodes\": [\n",
            "        {\n",
            "            \"name\": \"OpenAI NER\",\n",
            "            \"subtype\": \"openai_ner\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"e80b0e6b-cac5-4425-ae53-d97957eb7468\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"OpenAI Table to HTML\",\n",
            "            \"subtype\": \"openai_table2html\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"62d77501-3077-4b0f-a82e-9da8904a5c0e\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"OpenAI Table Description\",\n",
            "            \"subtype\": \"openai_table_description\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"6ef107c9-77dd-4561-90b0-5d9dd5920621\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"Partitioner\",\n",
            "            \"subtype\": \"unstructured_api\",\n",
            "            \"type\": \"partition\",\n",
            "            \"id\": \"ca01f853-89b5-456c-be0e-bc188572b133\",\n",
            "            \"settings\": {\n",
            "                \"strategy\": \"hi_res\",\n",
            "                \"include_page_breaks\": false,\n",
            "                \"pdf_infer_table_structure\": false,\n",
            "                \"exclude_elements\": null,\n",
            "                \"xml_keep_tags\": false,\n",
            "                \"encoding\": \"utf-8\",\n",
            "                \"extract_image_block_types\": [\n",
            "                    \"image\",\n",
            "                    \"table\"\n",
            "                ]\n",
            "            }\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"OpenAI Image Description\",\n",
            "            \"subtype\": \"openai_image_description\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"8921f656-a7fe-464f-9041-baa89f85cdce\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"Chunker\",\n",
            "            \"subtype\": \"chunk_by_character\",\n",
            "            \"type\": \"chunk\",\n",
            "            \"id\": \"54bede70-b47d-4ebe-ad01-b4247c332d4b\",\n",
            "            \"settings\": {\n",
            "                \"unstructured_api_url\": null,\n",
            "                \"unstructured_api_key\": null,\n",
            "                \"include_orig_elements\": true,\n",
            "                \"new_after_n_chars\": 400,\n",
            "                \"max_characters\": 500,\n",
            "                \"overlap\": 50,\n",
            "                \"overlap_all\": false,\n",
            "                \"contextual_chunking_strategy\": null\n",
            "            }\n",
            "        }\n",
            "    ],\n",
            "    \"reprocess_all\": true,\n",
            "    \"schedule\": {\n",
            "        \"crontab_entries\": []\n",
            "    },\n",
            "    \"updated_at\": \"2025-10-01T20:43:07.960275Z\",\n",
            "    \"workflow_type\": \"custom\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Run the following cell, which runs the workflow as a job and returns the job's ID.\n"
      ],
      "metadata": {
        "id": "BtRF4WRcEMZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "JOB_ID = run_workflow(CHINESE_CHARACTERS_INPUT_PATH)"
      ],
      "metadata": {
        "id": "d0nIGRmWlixR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Run the following cell, which keeps polling for job status until the job is finished."
      ],
      "metadata": {
        "id": "IQjqkuj4lUq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = poll_job_status(JOB_ID)\n",
        "print(f\"Job details:\\n---\\n{job.model_dump_json(indent=4)}\")"
      ],
      "metadata": {
        "id": "x3AlNgs7lryM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. After the job finishes successfully, run the following cell, which downloads Unstructured's output to the notebook's local `/content/output` subfolder."
      ],
      "metadata": {
        "id": "SIUrAm1rlazS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_info = get_job_download_details(JOB_ID)\n",
        "\n",
        "download_processed_file(\n",
        "    job_id=JOB_ID,\n",
        "    file_id=job_info.output_node_files[0].file_id,\n",
        "    node_id=job_info.output_node_files[0].node_id,\n",
        "    output_path=CHINESE_CHARACTERS_OUTPUT_PATH\n",
        ")"
      ],
      "metadata": {
        "id": "zn_dk7owlzPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Open the new version of this \"Chinese characters\" output file (if the version from the previous steps is already open, close it, and then open this new version instead). To explore the chunker's results, search for the text `\"type\": \"CompositeElement\"`.\n",
        "6. Now run the following cell, which changes the existing workflow's chunker node to chunk the document elements' text by using a title-based strategy."
      ],
      "metadata": {
        "id": "yrIqPUGCl4b3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "update_workflow_chunker_type(\n",
        "    subtype=\"chunk_by_title\",\n",
        "    max_characters=500,\n",
        "    new_after_n_characters=400,\n",
        "    overlap=50,\n",
        "    include_orig_elements=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POW3R9xUhIWX",
        "outputId": "0ad651ff-a5e8-4e06-fd2e-ec73c3c77326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workflow details:\n",
            "---\n",
            "{\n",
            "    \"created_at\": \"2025-09-30T18:04:14.558164Z\",\n",
            "    \"destinations\": [],\n",
            "    \"id\": \"ca99f800-8746-43e1-8f92-b6e36dbd22f8\",\n",
            "    \"name\": \"api-demo-workflow-2025-09-30-18-04-14\",\n",
            "    \"sources\": [],\n",
            "    \"status\": \"active\",\n",
            "    \"workflow_nodes\": [\n",
            "        {\n",
            "            \"name\": \"OpenAI NER\",\n",
            "            \"subtype\": \"openai_ner\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"e80b0e6b-cac5-4425-ae53-d97957eb7468\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"OpenAI Table to HTML\",\n",
            "            \"subtype\": \"openai_table2html\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"62d77501-3077-4b0f-a82e-9da8904a5c0e\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"OpenAI Table Description\",\n",
            "            \"subtype\": \"openai_table_description\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"6ef107c9-77dd-4561-90b0-5d9dd5920621\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"Partitioner\",\n",
            "            \"subtype\": \"unstructured_api\",\n",
            "            \"type\": \"partition\",\n",
            "            \"id\": \"ca01f853-89b5-456c-be0e-bc188572b133\",\n",
            "            \"settings\": {\n",
            "                \"strategy\": \"hi_res\",\n",
            "                \"include_page_breaks\": false,\n",
            "                \"pdf_infer_table_structure\": false,\n",
            "                \"exclude_elements\": null,\n",
            "                \"xml_keep_tags\": false,\n",
            "                \"encoding\": \"utf-8\",\n",
            "                \"extract_image_block_types\": [\n",
            "                    \"image\",\n",
            "                    \"table\"\n",
            "                ]\n",
            "            }\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"OpenAI Image Description\",\n",
            "            \"subtype\": \"openai_image_description\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"8921f656-a7fe-464f-9041-baa89f85cdce\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"Chunker\",\n",
            "            \"subtype\": \"chunk_by_title\",\n",
            "            \"type\": \"chunk\",\n",
            "            \"id\": \"d1fd5a94-7835-4ad7-946b-d718b53d2c4f\",\n",
            "            \"settings\": {\n",
            "                \"unstructured_api_url\": null,\n",
            "                \"unstructured_api_key\": null,\n",
            "                \"multipage_sections\": false,\n",
            "                \"combine_text_under_n_chars\": null,\n",
            "                \"include_orig_elements\": true,\n",
            "                \"new_after_n_chars\": 400,\n",
            "                \"max_characters\": 500,\n",
            "                \"overlap\": 50,\n",
            "                \"overlap_all\": false,\n",
            "                \"contextual_chunking_strategy\": null\n",
            "            }\n",
            "        }\n",
            "    ],\n",
            "    \"reprocess_all\": true,\n",
            "    \"schedule\": {\n",
            "        \"crontab_entries\": []\n",
            "    },\n",
            "    \"updated_at\": \"2025-10-01T20:44:44.478671Z\",\n",
            "    \"workflow_type\": \"custom\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Run the following cell, which runs the workflow as a job and returns the job's ID."
      ],
      "metadata": {
        "id": "ycKcd0z8muQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "JOB_ID = run_workflow(CHINESE_CHARACTERS_INPUT_PATH)"
      ],
      "metadata": {
        "id": "Wbd7QUl8nUDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Run the following cell, which keeps polling for job status until the job is finished."
      ],
      "metadata": {
        "id": "lHo724a-nQdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = poll_job_status(JOB_ID)\n",
        "print(f\"Job details:\\n---\\n{job.model_dump_json(indent=4)}\")"
      ],
      "metadata": {
        "id": "SQoq5o5TnaSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. After the job finishes successfully, run the following cell, which downloads Unstructured's output to the notebook's local `/content/output` subfolder."
      ],
      "metadata": {
        "id": "_RI83od1nwe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_info = get_job_download_details(JOB_ID)\n",
        "\n",
        "download_processed_file(\n",
        "    job_id=JOB_ID,\n",
        "    file_id=job_info.output_node_files[0].file_id,\n",
        "    node_id=job_info.output_node_files[0].node_id,\n",
        "    output_path=CHINESE_CHARACTERS_OUTPUT_PATH\n",
        ")"
      ],
      "metadata": {
        "id": "w06uJpoIn_mk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Open the new version of this \"Chinese characters\" output file (if the version from the previous steps is already open, close it, and then open this new version instead). To explore the chunker's results, search for the text `\"type\": \"CompositeElement\"`. Notice that the lengths of some of the chunks that immediately precede titles might be shortened due to the presence of the title impacting the chunk's size.\n",
        "11. Now run the following cell, which changes the existing workflow's chunker node to chunk the document elements' text by using a page-based strategy."
      ],
      "metadata": {
        "id": "WLVFsFidoLpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "update_workflow_chunker_type(\n",
        "    subtype=\"chunk_by_page\",\n",
        "    max_characters=500,\n",
        "    new_after_n_characters=400,\n",
        "    overlap=50,\n",
        "    include_orig_elements=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-Ys5UnThX-Y",
        "outputId": "262ca285-a549-4376-d78b-9b553d9e9ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workflow details:\n",
            "---\n",
            "{\n",
            "    \"created_at\": \"2025-09-30T18:04:14.558164Z\",\n",
            "    \"destinations\": [],\n",
            "    \"id\": \"ca99f800-8746-43e1-8f92-b6e36dbd22f8\",\n",
            "    \"name\": \"api-demo-workflow-2025-09-30-18-04-14\",\n",
            "    \"sources\": [],\n",
            "    \"status\": \"active\",\n",
            "    \"workflow_nodes\": [\n",
            "        {\n",
            "            \"name\": \"OpenAI NER\",\n",
            "            \"subtype\": \"openai_ner\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"e80b0e6b-cac5-4425-ae53-d97957eb7468\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"OpenAI Table to HTML\",\n",
            "            \"subtype\": \"openai_table2html\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"62d77501-3077-4b0f-a82e-9da8904a5c0e\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"OpenAI Table Description\",\n",
            "            \"subtype\": \"openai_table_description\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"6ef107c9-77dd-4561-90b0-5d9dd5920621\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"Partitioner\",\n",
            "            \"subtype\": \"unstructured_api\",\n",
            "            \"type\": \"partition\",\n",
            "            \"id\": \"ca01f853-89b5-456c-be0e-bc188572b133\",\n",
            "            \"settings\": {\n",
            "                \"strategy\": \"hi_res\",\n",
            "                \"include_page_breaks\": false,\n",
            "                \"pdf_infer_table_structure\": false,\n",
            "                \"exclude_elements\": null,\n",
            "                \"xml_keep_tags\": false,\n",
            "                \"encoding\": \"utf-8\",\n",
            "                \"extract_image_block_types\": [\n",
            "                    \"image\",\n",
            "                    \"table\"\n",
            "                ]\n",
            "            }\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"OpenAI Image Description\",\n",
            "            \"subtype\": \"openai_image_description\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"8921f656-a7fe-464f-9041-baa89f85cdce\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"Chunker\",\n",
            "            \"subtype\": \"chunk_by_page\",\n",
            "            \"type\": \"chunk\",\n",
            "            \"id\": \"3c62238c-e51b-4436-82de-83e90048a087\",\n",
            "            \"settings\": {\n",
            "                \"unstructured_api_url\": null,\n",
            "                \"unstructured_api_key\": null,\n",
            "                \"include_orig_elements\": true,\n",
            "                \"new_after_n_chars\": 400,\n",
            "                \"max_characters\": 500,\n",
            "                \"overlap\": 50,\n",
            "                \"overlap_all\": false,\n",
            "                \"contextual_chunking_strategy\": null\n",
            "            }\n",
            "        }\n",
            "    ],\n",
            "    \"reprocess_all\": true,\n",
            "    \"schedule\": {\n",
            "        \"crontab_entries\": []\n",
            "    },\n",
            "    \"updated_at\": \"2025-10-01T20:45:39.805434Z\",\n",
            "    \"workflow_type\": \"custom\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Run the following cell, which runs the workflow as a job and returns the job's ID."
      ],
      "metadata": {
        "id": "l3j-jY3RmwIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "JOB_ID = run_workflow(CHINESE_CHARACTERS_INPUT_PATH)"
      ],
      "metadata": {
        "id": "3chjNRHwnFMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Run the following cell, which keeps polling for job status until the job is finished."
      ],
      "metadata": {
        "id": "WfQQSB_fncQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = poll_job_status(JOB_ID)\n",
        "print(f\"Job details:\\n---\\n{job.model_dump_json(indent=4)}\")"
      ],
      "metadata": {
        "id": "eRRGCKrznnqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. After the job finishes successfully, run the following cell, which downloads Unstructured's output to the notebook's local `/content/output` subfolder."
      ],
      "metadata": {
        "id": "_dLIStE1n182"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_info = get_job_download_details(JOB_ID)\n",
        "\n",
        "download_processed_file(\n",
        "    job_id=JOB_ID,\n",
        "    file_id=job_info.output_node_files[0].file_id,\n",
        "    node_id=job_info.output_node_files[0].node_id,\n",
        "    output_path=CHINESE_CHARACTERS_OUTPUT_PATH\n",
        ")"
      ],
      "metadata": {
        "id": "LCJh4uYGoBad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Open the new version of this \"Chinese characters\" output file (if the version from the previous steps is already open, close it, and then open this new version instead). To explore the chunker's results, search for the text `\"type\": \"CompositeElement\"`. Notice that the lengths of some of the chunks that immediately precede page breaks might be shortened due to the presence of the page break impacting the chunk's size.\n",
        "16. Now run the following cell, which changes the existing workflow's chunker node to chunk the document elements' text by using a similarity-based strategy."
      ],
      "metadata": {
        "id": "9lk8wjwbocOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "update_workflow_chunker_type(\n",
        "    subtype=\"chunk_by_similarity\",\n",
        "    max_characters=500,\n",
        "    similarity_threshold=0.99,\n",
        "    include_orig_elements=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLxPEvZDhrH-",
        "outputId": "4e41a46b-b34f-4dac-db80-a76adf1a1a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workflow details:\n",
            "---\n",
            "{\n",
            "    \"created_at\": \"2025-09-30T18:04:14.558164Z\",\n",
            "    \"destinations\": [],\n",
            "    \"id\": \"ca99f800-8746-43e1-8f92-b6e36dbd22f8\",\n",
            "    \"name\": \"api-demo-workflow-2025-09-30-18-04-14\",\n",
            "    \"sources\": [],\n",
            "    \"status\": \"active\",\n",
            "    \"workflow_nodes\": [\n",
            "        {\n",
            "            \"name\": \"OpenAI NER\",\n",
            "            \"subtype\": \"openai_ner\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"e80b0e6b-cac5-4425-ae53-d97957eb7468\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"OpenAI Table to HTML\",\n",
            "            \"subtype\": \"openai_table2html\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"62d77501-3077-4b0f-a82e-9da8904a5c0e\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"OpenAI Table Description\",\n",
            "            \"subtype\": \"openai_table_description\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"6ef107c9-77dd-4561-90b0-5d9dd5920621\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"Partitioner\",\n",
            "            \"subtype\": \"unstructured_api\",\n",
            "            \"type\": \"partition\",\n",
            "            \"id\": \"ca01f853-89b5-456c-be0e-bc188572b133\",\n",
            "            \"settings\": {\n",
            "                \"strategy\": \"hi_res\",\n",
            "                \"include_page_breaks\": false,\n",
            "                \"pdf_infer_table_structure\": false,\n",
            "                \"exclude_elements\": null,\n",
            "                \"xml_keep_tags\": false,\n",
            "                \"encoding\": \"utf-8\",\n",
            "                \"extract_image_block_types\": [\n",
            "                    \"image\",\n",
            "                    \"table\"\n",
            "                ]\n",
            "            }\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"OpenAI Image Description\",\n",
            "            \"subtype\": \"openai_image_description\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"8921f656-a7fe-464f-9041-baa89f85cdce\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"Chunker\",\n",
            "            \"subtype\": \"chunk_by_similarity\",\n",
            "            \"type\": \"chunk\",\n",
            "            \"id\": \"785aa571-1186-47f7-996c-81d24924a545\",\n",
            "            \"settings\": {\n",
            "                \"unstructured_api_url\": null,\n",
            "                \"unstructured_api_key\": null,\n",
            "                \"include_orig_elements\": true,\n",
            "                \"new_after_n_chars\": null,\n",
            "                \"max_characters\": 500,\n",
            "                \"overlap\": null,\n",
            "                \"overlap_all\": false,\n",
            "                \"contextual_chunking_strategy\": null,\n",
            "                \"similarity_threshold\": 0.99\n",
            "            }\n",
            "        }\n",
            "    ],\n",
            "    \"reprocess_all\": true,\n",
            "    \"schedule\": {\n",
            "        \"crontab_entries\": []\n",
            "    },\n",
            "    \"updated_at\": \"2025-10-01T20:48:11.056790Z\",\n",
            "    \"workflow_type\": \"custom\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Run the following cell, which runs the workflow as a job and returns the job's ID."
      ],
      "metadata": {
        "id": "6v0f1jpUqHGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "JOB_ID = run_workflow(CHINESE_CHARACTERS_INPUT_PATH)"
      ],
      "metadata": {
        "id": "t6gR3ynUqXoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Run the following cell, which keeps polling for job status until the job is finished."
      ],
      "metadata": {
        "id": "4vZYSbKoqIyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = poll_job_status(JOB_ID)\n",
        "print(f\"Job details:\\n---\\n{job.model_dump_json(indent=4)}\")"
      ],
      "metadata": {
        "id": "uWGE3RqwqbcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. After the job finishes successfully, run the following cell, which downloads Unstructured's output to the notebook's local `/content/output` subfolder."
      ],
      "metadata": {
        "id": "xSdhqh5EqNED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_info = get_job_download_details(JOB_ID)\n",
        "\n",
        "download_processed_file(\n",
        "    job_id=JOB_ID,\n",
        "    file_id=job_info.output_node_files[0].file_id,\n",
        "    node_id=job_info.output_node_files[0].node_id,\n",
        "    output_path=CHINESE_CHARACTERS_OUTPUT_PATH\n",
        ")"
      ],
      "metadata": {
        "id": "Z1VhrA4pqm5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Open the new version of this \"Chinese characters\" output file (if the version from the previous steps is already open, close it, and then open this new version instead). To explore the chunker's results, search for the text `\"type\": \"CompositeElement\"`. Notice that the lengths of many of the chunks fall well short of the `max_characters` limit. This is because a similarity threshold of `0.99` means that only sentences or text segments with a near-perfect semantic match will be grouped together into the same chunk. This is an extremely high threshold, resulting in very short, highly specific chunks of text.\n",
        "21. Now run the following cell, which changes the existing workflow's chunker node to use a different similarity threshold."
      ],
      "metadata": {
        "id": "tlVj8cXRox4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "update_workflow_chunker_type(\n",
        "    subtype=\"chunk_by_similarity\",\n",
        "    max_characters=500,\n",
        "    similarity_threshold=0.01,\n",
        "    include_orig_elements=True\n",
        ")"
      ],
      "metadata": {
        "id": "stLH7t6BiMT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Run the following cell, which runs the workflow as a job and returns the job's ID."
      ],
      "metadata": {
        "id": "4cZQ-2fxm0_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "JOB_ID = run_workflow(CHINESE_CHARACTERS_INPUT_PATH)"
      ],
      "metadata": {
        "id": "7aYROISPnHN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Run the following cell, which keeps polling for job status until the job is finished."
      ],
      "metadata": {
        "id": "6jXHRkfNneck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = poll_job_status(JOB_ID)\n",
        "print(f\"Job details:\\n---\\n{job.model_dump_json(indent=4)}\")"
      ],
      "metadata": {
        "id": "BznK1bGNnpEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. After the job finishes successfully, run the following cell, which downloads Unstructured's output to the notebook's local `/content/output` subfolder."
      ],
      "metadata": {
        "id": "HLPjkT4Ln3jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_info = get_job_download_details(JOB_ID)\n",
        "\n",
        "download_processed_file(\n",
        "    job_id=JOB_ID,\n",
        "    file_id=job_info.output_node_files[0].file_id,\n",
        "    node_id=job_info.output_node_files[0].node_id,\n",
        "    output_path=CHINESE_CHARACTERS_OUTPUT_PATH\n",
        ")"
      ],
      "metadata": {
        "id": "9ujAjPTtoDS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Open the new version of this \"Chinese characters\" output file (if the version from the previous steps is already open, close it, and then open this new version instead). To explore the chunker's results, search for the text `\"type\": \"CompositeElement\"`. Notice now that many of the chunks will now come closer to the `max_characters` limit. This is because a similarity threshold of `0.01` provides an extreme tolerance of differences between pieces of text, grouping almost anything together."
      ],
      "metadata": {
        "id": "WBPrbV9wpItQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Experiment with embedding"
      ],
      "metadata": {
        "id": "fvV4mg8ri3Sf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, you generate [embeddings](https://docs.unstructured.io/ui/embedding) for your workflow. Embeddings are vectors of numbers that represent various aspects of the text that is extracted by Unstructured. These vectors are stored or \"embedded\" next to the text itself in a vector store or vector database. Chatbots, agents, and other AI solutions can use these vector embeddings to more efficiently and effectively find, analyze, and use the associated text. These vector embeddings are generated by an embedding model that is provided by an embedding provider. For the best embedding model to apply to your use case, see the documentation for your target downstream application toolsets.\n"
      ],
      "metadata": {
        "id": "zh2Aott6rCHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Run the following cell, which changes the existing workflow to add a workflow node that uses the `text-embedding-3-small` embedding model provided by Azure OpenAI."
      ],
      "metadata": {
        "id": "pITHIeimruiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unstructured_client import UnstructuredClient\n",
        "from unstructured_client.models.shared import (\n",
        "    WorkflowNode,\n",
        "    UpdateWorkflow,\n",
        "    WorkflowType\n",
        ")\n",
        "from unstructured_client.models.operations import UpdateWorkflowRequest\n",
        "\n",
        "with UnstructuredClient(api_key_auth=UNSTRUCTURED_API_KEY) as client:\n",
        "    partition_node = WorkflowNode(\n",
        "        name=\"Partitioner\",\n",
        "        subtype=\"unstructured_api\",\n",
        "        type=\"partition\",\n",
        "        settings={\n",
        "            \"strategy\": \"hi_res\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    image_description_enrichment_node = WorkflowNode(\n",
        "        name=\"OpenAI Image Description\",\n",
        "        subtype=\"openai_image_description\",\n",
        "        type=\"prompter\",\n",
        "        settings={}\n",
        "    )\n",
        "\n",
        "    table_description_enrichment_node = WorkflowNode(\n",
        "        name=\"OpenAI Table Description\",\n",
        "        subtype=\"openai_table_description\",\n",
        "        type=\"prompter\",\n",
        "        settings={}\n",
        "    )\n",
        "\n",
        "    table_to_html_enrichment_node = WorkflowNode(\n",
        "        name=\"OpenAI Table to HTML\",\n",
        "        subtype=\"openai_table2html\",\n",
        "        type=\"prompter\",\n",
        "        settings={}\n",
        "    )\n",
        "\n",
        "    named_entity_recognition_enrichment_node = WorkflowNode(\n",
        "        name=\"OpenAI NER\",\n",
        "        subtype=\"openai_ner\",\n",
        "        type=\"prompter\",\n",
        "        settings={}\n",
        "    )\n",
        "\n",
        "    chunker_node = WorkflowNode(\n",
        "        name=\"Chunker\",\n",
        "        subtype=\"chunk_by_character\",\n",
        "        type=\"chunk\",\n",
        "        settings={\n",
        "            \"max_characters\": 500,\n",
        "            \"new_after_n_chars\": 400,\n",
        "            \"overlap\": 50,\n",
        "            \"include_orig_elements\": True\n",
        "        }\n",
        "    )\n",
        "\n",
        "    embedder_node = WorkflowNode(\n",
        "        name=\"Embedder\",\n",
        "        subtype=\"azure_openai\",\n",
        "        type=\"embed\",\n",
        "        settings={\n",
        "            \"model_name\": \"text-embedding-3-small\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    workflow = UpdateWorkflow(\n",
        "        workflow_type=WorkflowType.CUSTOM,\n",
        "        workflow_nodes=[\n",
        "            partition_node,\n",
        "            image_description_enrichment_node,\n",
        "            table_description_enrichment_node,\n",
        "            table_to_html_enrichment_node,\n",
        "            named_entity_recognition_enrichment_node,\n",
        "            chunker_node,\n",
        "            embedder_node\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    response = client.workflows.update_workflow(\n",
        "        request=UpdateWorkflowRequest(\n",
        "            workflow_id=WORKFLOW_ID,\n",
        "            update_workflow=workflow\n",
        "        )\n",
        "    )\n",
        "\n",
        "    print(f\"Workflow details:\\n---\\n{response.workflow_information.model_dump_json(indent=4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLI011qWjE2U",
        "outputId": "1754b4d3-68e3-4346-d07e-3c832f24f38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workflow details:\n",
            "---\n",
            "{\n",
            "    \"created_at\": \"2025-09-30T18:04:14.558164Z\",\n",
            "    \"destinations\": [],\n",
            "    \"id\": \"ca99f800-8746-43e1-8f92-b6e36dbd22f8\",\n",
            "    \"name\": \"api-demo-workflow-2025-09-30-18-04-14\",\n",
            "    \"sources\": [],\n",
            "    \"status\": \"active\",\n",
            "    \"workflow_nodes\": [\n",
            "        {\n",
            "            \"name\": \"OpenAI NER\",\n",
            "            \"subtype\": \"openai_ner\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"e80b0e6b-cac5-4425-ae53-d97957eb7468\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"OpenAI Table to HTML\",\n",
            "            \"subtype\": \"openai_table2html\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"62d77501-3077-4b0f-a82e-9da8904a5c0e\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"OpenAI Table Description\",\n",
            "            \"subtype\": \"openai_table_description\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"6ef107c9-77dd-4561-90b0-5d9dd5920621\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"Partitioner\",\n",
            "            \"subtype\": \"unstructured_api\",\n",
            "            \"type\": \"partition\",\n",
            "            \"id\": \"ca01f853-89b5-456c-be0e-bc188572b133\",\n",
            "            \"settings\": {\n",
            "                \"strategy\": \"hi_res\",\n",
            "                \"include_page_breaks\": false,\n",
            "                \"pdf_infer_table_structure\": false,\n",
            "                \"exclude_elements\": null,\n",
            "                \"xml_keep_tags\": false,\n",
            "                \"encoding\": \"utf-8\",\n",
            "                \"extract_image_block_types\": [\n",
            "                    \"image\",\n",
            "                    \"table\"\n",
            "                ]\n",
            "            }\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"OpenAI Image Description\",\n",
            "            \"subtype\": \"openai_image_description\",\n",
            "            \"type\": \"prompter\",\n",
            "            \"id\": \"8921f656-a7fe-464f-9041-baa89f85cdce\",\n",
            "            \"settings\": {}\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"Embedder\",\n",
            "            \"subtype\": \"azure_openai\",\n",
            "            \"type\": \"embed\",\n",
            "            \"id\": \"9df0a326-b2de-44ad-aef4-b789eea4f976\",\n",
            "            \"settings\": {\n",
            "                \"model_name\": \"text-embedding-3-small\"\n",
            "            }\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"Chunker\",\n",
            "            \"subtype\": \"chunk_by_character\",\n",
            "            \"type\": \"chunk\",\n",
            "            \"id\": \"da35169c-e40f-4425-8a06-a1db5e79d307\",\n",
            "            \"settings\": {\n",
            "                \"unstructured_api_url\": null,\n",
            "                \"unstructured_api_key\": null,\n",
            "                \"include_orig_elements\": true,\n",
            "                \"new_after_n_chars\": 400,\n",
            "                \"max_characters\": 500,\n",
            "                \"overlap\": 50,\n",
            "                \"overlap_all\": false,\n",
            "                \"contextual_chunking_strategy\": null\n",
            "            }\n",
            "        }\n",
            "    ],\n",
            "    \"reprocess_all\": true,\n",
            "    \"schedule\": {\n",
            "        \"crontab_entries\": []\n",
            "    },\n",
            "    \"updated_at\": \"2025-10-01T21:29:44.456385Z\",\n",
            "    \"workflow_type\": \"custom\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Run the following cell, which runs the workflow as a job and returns the job's ID."
      ],
      "metadata": {
        "id": "ZSYhwwmgsK4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "JOB_ID = run_workflow(CHINESE_CHARACTERS_INPUT_PATH)"
      ],
      "metadata": {
        "id": "R5jcQT3EstC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Run the following cell, which keeps polling for job status until the job is finished."
      ],
      "metadata": {
        "id": "0GOMS9aOsPba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = poll_job_status(JOB_ID)\n",
        "print(f\"Job details:\\n---\\n{job.model_dump_json(indent=4)}\")"
      ],
      "metadata": {
        "id": "aF08fu9bsxcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. After the job finishes successfully, run the following cell, which downloads Unstructured's output to the notebook's local `/content/output` subfolder."
      ],
      "metadata": {
        "id": "Bw6tLGMEsUp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_info = get_job_download_details(JOB_ID)\n",
        "\n",
        "download_processed_file(\n",
        "    job_id=JOB_ID,\n",
        "    file_id=job_info.output_node_files[0].file_id,\n",
        "    node_id=job_info.output_node_files[0].node_id,\n",
        "    output_path=CHINESE_CHARACTERS_OUTPUT_PATH\n",
        ")"
      ],
      "metadata": {
        "id": "_aWYXlrjs1e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Open the new version of this \"Chinese characters\" output file (if the version from the previous steps is already open, close it, and then open this new version instead). To explore the embeddings, search for the text `\"embeddings\"`.\n",
        "\n",
        "---\n",
        ">\n",
        "> 💡 _What do all of these numbers mean?_\n",
        ">\n",
        "> All by themselves, the numbers in the `embeddings` field of the output have\n",
        "> no human-interpretable meaning on their own. However, when combined with the\n",
        "> specific text that these numbers are associated with, and the embedding\n",
        "> model's logic that was used to generate these numbers, the numbers in the\n",
        "> `embeddings` field are extremely powerful when leveraged by downstream\n",
        "> chatbots, agents, and other AI solutions.\n",
        ">\n",
        "> These numbers typically represent complex, abstract attributes about the text\n",
        "> that are known only to the embedding model that generated these numbers.\n",
        "> These attributes can be about the text's overall sentiment, intent, subject,\n",
        "> semantic meaning, grammatical function, relationships between words, or any\n",
        "> number of other things that the model is good at figuring out. This is why\n",
        "> the embedding model you choose here must be the exact same embedding model\n",
        "> that you use in any related chatbot, agent, or other AI solution that relies\n",
        "> on these numbers. Otherwise, the numbers that are generated here will not\n",
        "> have the same meaning downstream as well. Also, the number of dimensions (or\n",
        "> the number of numbers in the `embeddings` field) you choose here must also be\n",
        "> the exact same number of dimensions downstream as well.\n",
        ">\n",
        "> To repeat, the name and number of dimensions for the embedding model you\n",
        "> choose here must be the exact same name and number of dimensions for the\n",
        "> embedding model you use in your related downstream chatbots, agents, and\n",
        "> other AI solutions that rely on this particular text and its associated\n",
        "> embeddings that were generated here."
      ],
      "metadata": {
        "id": "S1bfac4gsdFV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next steps"
      ],
      "metadata": {
        "id": "aIq1Bljls7z1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations! You now have an Unstructured workflow that partitions, enriches, chunks, and embeds your source documents, producing context-rich data that is ready for retrieval-augmented generation (RAG), agentic AI, and model fine-tuning.\n",
        "\n",
        "Right now, your workflow only accepts one local file at a time for input. Your workflow also only sends Unstructured's processed data to your screen or to be saved locally as a JSON file. You can modify your workflow to accept multiple files and data from&mdash;and send Unstructured's processed data to&mdash;one or more file storage locations, databases, and vector stores. To learn how to do this, try the [Dropbox-to-Pinecone Connector API Quickstart for Unstructured](https://colab.research.google.com/github/Unstructured-IO/notebooks/blob/main/notebooks/Dropbox_To_Pinecone_Connector_Quickstart.ipynb) notebook.\n",
        "\n",
        "Unstructured also offers a user interface (UI), which allows you to use a graphical user interface to work with Unstructured instead of only with the API. For details, see the [Unstructured UI Overview](https://docs.unstructured.io/ui/overview).\n",
        "\n",
        "If you are not able to complete any of the preceding quickstarts, contact Unstructured Support at [support@unstructured.io](mailto:support@unstructured.io)."
      ],
      "metadata": {
        "id": "v3pp92gys-_d"
      }
    }
  ]
}