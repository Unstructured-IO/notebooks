{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlCIp1_-TWqh"
      },
      "source": [
        "# Building Graph-Based RAG Applications Is Finally Easy\n",
        "\n",
        "## Unstructured API tutorial for writing data with NER enrichment to your Astra DB\n",
        "\n",
        "See [blog](https://thenewstack.io/building-graph-based-rag-applications-just-got-easier/) for the full Graph RAG workflow and to see how to effortlessly build a knowledge Graph in Astra DB leveraging Unstructured\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdWG7kkGT8IF"
      },
      "source": [
        "Unstructured’s ETL+ for GenAI continuously harvesting newly generated unstructured data from systems of record, transforming it into LLM-ready formats using optimized, pre-built pipelines, and writing it to Astra DB. You can deploy complete  ingestion and preprocessing pipelines in seconds, with configuration options and third party integrations for the partitioning, enrichment, chunking, and embedding steps. This enables knowledge graph building without needing to write any code or create any custom steps. The critical NER enrichment step can be easily configured within the full ETL+ pipeline that is available in Unstructured [UI](https://platform.unstructured.io/) or API (below)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoEYxX8yUWSW"
      },
      "source": [
        "## 1. Installs + credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADL5S0UaswAN",
        "outputId": "2a1910e6-ae39-4b57-dc07-6ea73de2b25b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/60.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain-openai openai langchain-graph-retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJbIZ8KNs0S_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY') # Your OpenAI API key\n",
        "\n",
        "os.environ[\"S3_AWS_KEY\"] = userdata.get('AWS_ACCESS_KEY_ID')\n",
        "os.environ[\"S3_AWS_SECRET\"] = userdata.get('AWS_SECRET_ACCESS_KEY')\n",
        "os.environ[\"S3_REMOTE_URL\"] = userdata.get('AWS_S3_URL')\n",
        "\n",
        "\n",
        "\n",
        "os.environ[\"ASTRA_DB_APPLICATION_TOKEN\"] = userdata.get('ASTRA_DB_APPLICATION_TOKEN')\n",
        "os.environ[\"ASTRA_DB_API_ENDPOINT\"] = userdata.get('ASTRA_DB_API_ENDPOINT')\n",
        "os.environ[\"ASTRA_DB_COLLECTION_NAME\"] = userdata.get('ASTRA_DB_COLLECTION_NAME')\n",
        "os.environ[\"ASTRA_DB_KEYSPACE\"] = userdata.get('ASTRA_DB_KEYSPACE')\n",
        "os.environ['UNSTRUCTURED_API_KEY'] = userdata.get('UNSTRUCTURED_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgZZeIhTtAxE"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade -q \"unstructured-client\"  astrapy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOjCKdF8tDYw"
      },
      "outputs": [],
      "source": [
        "from unstructured_client import UnstructuredClient\n",
        "from unstructured_client.models.operations import CreateSourceRequest\n",
        "from unstructured_client.models.shared import CreateSourceConnector\n",
        "from unstructured_client.models.operations import CreateDestinationRequest\n",
        "from unstructured_client.models.shared import CreateDestinationConnector\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YIJHGHdts8S"
      },
      "source": [
        "## 2. Create S3 Source Connector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f9O3rw2tutH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from unstructured_client import UnstructuredClient\n",
        "from unstructured_client.models.operations import CreateSourceRequest\n",
        "from unstructured_client.models.shared import (\n",
        "    CreateSourceConnector,\n",
        "    SourceConnectorType,\n",
        "    S3SourceConnectorConfigInput\n",
        ")\n",
        "\n",
        "with UnstructuredClient(api_key_auth=os.getenv(\"UNSTRUCTURED_API_KEY\")) as client:\n",
        "    source_response = client.sources.create_source(\n",
        "        request=CreateSourceRequest(\n",
        "            create_source_connector=CreateSourceConnector(\n",
        "                name=\"graphrag_s3_source\",\n",
        "                type=SourceConnectorType.S3,\n",
        "                config=S3SourceConnectorConfigInput(\n",
        "\n",
        "\n",
        "                    key=os.environ.get('S3_AWS_KEY'),\n",
        "                    secret=os.environ.get('S3_AWS_SECRET'),\n",
        "\n",
        "\n",
        "\n",
        "                    remote_url=os.environ.get('S3_REMOTE_URL'),\n",
        "                    recursive=True\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUwyYcnkx5g9",
        "outputId": "99c9b2c2-cf32-4328-fa61-ddf99dbbb933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "config=S3SourceConnectorConfig(anonymous=False, recursive=True, remote_url='s3://nina-test-platform/test-mini/', endpoint_url=Unset(), key='**********', secret='**********', token=Unset()) created_at=datetime.datetime(2025, 3, 26, 20, 39, 13, 646221, tzinfo=TzInfo(UTC)) id='05f18931-c3fd-4f43-896a-570093c1edb8' name='graphrag_s3_source' type=<SourceConnectorType.S3: 's3'> updated_at=datetime.datetime(2025, 3, 26, 20, 39, 14, 112052, tzinfo=TzInfo(UTC))\n"
          ]
        }
      ],
      "source": [
        "print(source_response.source_connector_information)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky0mNokuuMPK"
      },
      "source": [
        "## 3. Create Astra DB Destination Connector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2njHuMJtvRW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from unstructured_client import UnstructuredClient\n",
        "from unstructured_client.models.operations import CreateDestinationRequest\n",
        "from unstructured_client.models.shared import (\n",
        "    CreateDestinationConnector,\n",
        "    DestinationConnectorType,\n",
        "    AstraDBConnectorConfigInput\n",
        ")\n",
        "\n",
        "with UnstructuredClient(api_key_auth=os.getenv(\"UNSTRUCTURED_API_KEY\")) as client:\n",
        "    destination_response = client.destinations.create_destination(\n",
        "        request=CreateDestinationRequest(\n",
        "            create_destination_connector=CreateDestinationConnector(\n",
        "                name=\"graphrag_astra_destination\",\n",
        "                type=DestinationConnectorType.ASTRADB,\n",
        "                config=AstraDBConnectorConfigInput(\n",
        "                    token=os.environ.get('ASTRA_DB_APPLICATION_TOKEN'),\n",
        "                    api_endpoint=os.environ.get('ASTRA_DB_API_ENDPOINT'),\n",
        "                    collection_name=os.environ.get('ASTRA_DB_COLLECTION_NAME'),\n",
        "                    keyspace=os.environ.get('ASTRA_DB_KEYSPACE'),\n",
        "                    batch_size=20,\n",
        "                    flatten_metadata=True\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k89oaN4y2Vh",
        "outputId": "631db238-7bef-4549-cc8e-2d23fb8ab083"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "config=AstraDBConnectorConfig(api_endpoint='**********', batch_size=20, collection_name='graph_vectorstore', token='**********', keyspace='default_keyspace') created_at=datetime.datetime(2025, 3, 26, 20, 39, 14, 412404, tzinfo=TzInfo(UTC)) id='2905af93-d681-4a42-a684-981cf250b7a0' name='graphrag_astra_destination' type=<DestinationConnectorType.ASTRADB: 'astradb'> updated_at=datetime.datetime(2025, 3, 26, 20, 39, 14, 840293, tzinfo=TzInfo(UTC))\n"
          ]
        }
      ],
      "source": [
        "print(destination_response.destination_connector_information)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzY8iFYHvtqZ"
      },
      "source": [
        "## 4. Creating Nodes for Workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp1KWkQmUgmU"
      },
      "source": [
        "Note that the named_entity_recognizer_node will be creating the metadata for nodes and edges, and that it is critical to place it after the chunking node, whether you are creating your workflow via UI or API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucdQ1QkuuO1_"
      },
      "outputs": [],
      "source": [
        "from unstructured_client.models.shared import (\n",
        "    WorkflowNode,\n",
        "    WorkflowNodeType,\n",
        "    WorkflowType,\n",
        "    Schedule\n",
        ")\n",
        "\n",
        "# Partition the content by using a vision language model (VLM).\n",
        "partition_node = WorkflowNode(\n",
        "    name=\"Partitioner\",\n",
        "    subtype=\"vlm\",\n",
        "    type=WorkflowNodeType.PARTITION,\n",
        "    settings={\n",
        "        \"provider\": \"anthropic\",\n",
        "        \"provider_api_key\": None,\n",
        "        \"model\": \"claude-sonnet-4-5-20250929\",\n",
        "        \"output_format\": \"text/html\",\n",
        "        \"user_prompt\": None,\n",
        "        \"format_html\": True,\n",
        "        \"unique_element_ids\": True,\n",
        "        \"is_dynamic\": True,\n",
        "        \"allow_fast\": True\n",
        "    }\n",
        ")\n",
        "\n",
        "# Summarize each detected image.\n",
        "image_summarizer_node = WorkflowNode(\n",
        "    name=\"Image summarizer\",\n",
        "    subtype=\"openai_image_description\",\n",
        "    type=WorkflowNodeType.PROMPTER,\n",
        "    settings={}\n",
        ")\n",
        "\n",
        "# Summarize each detected table.\n",
        "table_summarizer_node = WorkflowNode(\n",
        "    name=\"Table summarizer\",\n",
        "    subtype=\"anthropic_table_description\",\n",
        "    type=WorkflowNodeType.PROMPTER,\n",
        "    settings={}\n",
        ")\n",
        "\n",
        "# Chunk the partitioned content.\n",
        "chunk_node = WorkflowNode(\n",
        "    name=\"Chunker\",\n",
        "    subtype=\"chunk_by_title\",\n",
        "    type=WorkflowNodeType.CHUNK,\n",
        "    settings={\n",
        "        \"unstructured_api_url\": None,\n",
        "        \"unstructured_api_key\": None,\n",
        "        \"multipage_sections\": False,\n",
        "        \"combine_text_under_n_chars\": 0,\n",
        "        \"include_orig_elements\": True,\n",
        "        \"new_after_n_chars\": 1500,\n",
        "        \"max_characters\": 2048,\n",
        "        \"overlap\": 160,\n",
        "        \"overlap_all\": False,\n",
        "        \"contextual_chunking_strategy\": None\n",
        "    }\n",
        ")\n",
        "\n",
        "# Label each recognized named entity.\n",
        "named_entity_recognizer_node = WorkflowNode(\n",
        "    name=\"Named entity recognizer\",\n",
        "    subtype=\"openai_ner\",\n",
        "    type=WorkflowNodeType.PROMPTER,\n",
        "    settings={\n",
        "        \"prompt_interface_overrides\": {\n",
        "            \"prompt\": {\n",
        "                \"user\": (\n",
        "                    \"Extract all named entities, including people and locations, from the given text segments \"\n",
        "                    \"and provide structured metadata for each entity identified.\\n\\n\"\n",
        "                    'Response format: {\"PLACES\": [\"England\", \"Middlesex\"]}'\n",
        "                )\n",
        "            }\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# Generate vector embeddings.\n",
        "embed_node = WorkflowNode(\n",
        "    name=\"Embedder\",\n",
        "    subtype=\"azure_openai\",\n",
        "    type=WorkflowNodeType.EMBED,\n",
        "    settings={\n",
        "        \"model_name\": \"text-embedding-3-large\"\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDi_Yi_wUsu5"
      },
      "source": [
        "## 5. Set up the workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6kPigB3zbXC",
        "outputId": "4c147ac0-689f-491f-a2db-ca25a1f3a96c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name:           s3-to-astra-Graph-RAG-workflow-2025-03-26-20-43-14\n",
            "id:             5c8117eb-c507-4ef2-9f82-7590147344d4\n",
            "status:         WorkflowState.ACTIVE\n",
            "type:           WorkflowType.CUSTOM\n",
            "source(s):\n",
            "            05f18931-c3fd-4f43-896a-570093c1edb8\n",
            "destination(s):\n",
            "            2905af93-d681-4a42-a684-981cf250b7a0\n",
            "schedule(s):\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "from unstructured_client.models.shared import (\n",
        "    WorkflowNode,\n",
        "    WorkflowNodeType,\n",
        "    CreateWorkflow,\n",
        "    WorkflowType,\n",
        "    Schedule\n",
        ")\n",
        "from unstructured_client.models.operations import CreateWorkflowRequest\n",
        "\n",
        "unique_workflow_suffix = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "workflow = CreateWorkflow(\n",
        "    name=f\"s3-to-astra-Graph-RAG-workflow-{unique_workflow_suffix}\",\n",
        "    source_id=source_response.source_connector_information.id,\n",
        "    destination_id=destination_response.destination_connector_information.id,\n",
        "    workflow_type=WorkflowType.CUSTOM,\n",
        "    workflow_nodes=[\n",
        "        partition_node,\n",
        "        image_summarizer_node,\n",
        "        table_summarizer_node,\n",
        "        chunk_node,\n",
        "        named_entity_recognizer_node,\n",
        "        embed_node\n",
        "    ],\n",
        ")\n",
        "\n",
        "client = UnstructuredClient(\n",
        "    api_key_auth=os.getenv(\"UNSTRUCTURED_API_KEY\")\n",
        ")\n",
        "response = client.workflows.create_workflow(\n",
        "    request=CreateWorkflowRequest(\n",
        "        create_workflow=workflow\n",
        "    )\n",
        ")\n",
        "\n",
        "info = response.workflow_information\n",
        "\n",
        "print(f\"name:           {info.name}\")\n",
        "print(f\"id:             {info.id}\")\n",
        "print(f\"status:         {info.status}\")\n",
        "print(f\"type:           {info.workflow_type}\")\n",
        "print(\"source(s):\")\n",
        "\n",
        "for source in info.sources:\n",
        "    print(f\"            {source}\")\n",
        "\n",
        "print(\"destination(s):\")\n",
        "\n",
        "for destination in info.destinations:\n",
        "    print(f\"            {destination}\")\n",
        "\n",
        "print(\"schedule(s):\")\n",
        "\n",
        "for crontab_entry in info.schedule.crontab_entries:\n",
        "    print(f\"            {crontab_entry.cron_expression}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJI0oK3LUzsu"
      },
      "source": [
        "## 6. Run the workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1Oi9Xvm0QBv",
        "outputId": "cd9b3422-1b60-4d6a-9275-06bb64bedbd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Response [202 Accepted]>\n"
          ]
        }
      ],
      "source": [
        "from unstructured_client.models.operations import RunWorkflowRequest\n",
        "\n",
        "response = client.workflows.run_workflow(\n",
        "    request=RunWorkflowRequest(\n",
        "        workflow_id=info.id\n",
        "    )\n",
        ")\n",
        "\n",
        "print(response.raw_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdGDrNGTVArE"
      },
      "source": [
        "## Now your data is in your Astra DB, you can check your Collection there, or go to your Unstructured UI to see the Workflow + results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EeVFm5nVIA2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
