{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWVpkbEA2QR_"
      },
      "source": [
        "# Use Unstructured with Snowflake Cortex Search for RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sh9QKGN2ac5"
      },
      "source": [
        "This notebook demonstrates how to use Unstructured to process one or more source documents in an Amazon S3 bucket, adding the documents' processed data to a Snowflake table. From there, this notebook demonstrates how to use [Snowflake Cortex](https://www.snowflake.com/product/features/cortex/) to search the table's contents with natural-language queries using retrieval-augmented generation (RAG).\n",
        "\n",
        "To perform RAG search, three Snowflake functions are highlighted in this notebook:\n",
        "\n",
        "- [SNOWFLAKE.CORTEX.EMBED_TEXT_1024](https://docs.snowflake.com/sql-reference/functions/embed_text_1024-snowflake-cortex), which creates a vector embedding of 1024 dimensions from the text in the table and the text for the natural-language query's text.\n",
        "- [VECTOR_COSINE_SIMILARITY](https://docs.snowflake.com/sql-reference/functions/vector_cosine_similarity), which computes the cosine similarity between two vectors. In this notebook, the vector for the text in each of the table's records and the vector for the query text are compared. The table record with the highest positive similarity (closest to 1) is then used. When determining the highest similarity, identical vectors have a cosine similarity of 1 (which means they likely represent the same meaning or concept); two orthogonal vectors have a similarity of 0 (which means they are not semantically related--such as \"dog\" and \"car\"); and two opposite vectors have a similarity of -1 (which means they have opposing semantic meanings--such as \"hot\" and \"cold\").\n",
        "- [SNOWFLAKE.CORTEX.COMPLETE](https://docs.snowflake.com/sql-reference/functions/complete-snowflake-cortex), which uses the natural-language query, the table record with the highest positive cosine similarity, and a large language model (LLM) to generate a natural-language response to the query.\n",
        "\n",
        "At the end of this notebook, you can optionally experiment with additional Snowflake Cortex functions that perform tasks such as sentiment analysis, simple Q&A, language translation, and text classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_SmLPer2eXp"
      },
      "source": [
        "## Requirements\n",
        "\n",
        "To complete this notebook, you will need:\n",
        "\n",
        "- An Unstructured account. Go to [https://platform.unstructured.io](https://platform.unstructured.io) and use your email address, Google account, or GitHub account to sign up for an Unstructured account (if you do not already have one) and sign into the account at the same time.\n",
        "- An Unstructured API key for your account. To get this API key, after you sign in to your Unstructured account:\n",
        "\n",
        "  1. In the Unstructured user interface (UI), click **API Keys** on the sidebar.\n",
        "  2. Click **Generate API Key**.\n",
        "  3. Follow the on-screen instructions to finish generating the key.\n",
        "  4. Click the **Copy** icon next to your new key to add the key to your system's clipboard. If you lose this key, simply return and click the **Copy** icon again.\n",
        "\n",
        "You will also need, for Amazon S3:\n",
        "\n",
        "1. An Amazon Web Services (AWS) account, along with your AWS secret key and AWS secret access key for authentication. You'll also need Amazon S3 bucket with the correct access settings applied.\n",
        "2. One or more documents uploaded to the S3 bucket. These are the documents that Unstructured will process, sending the documents' processed data into your Snowflake table. If you don't have any documents readily available to upload into the S3 bucket, you can grab some from the [example-docs](https://github.com/Unstructured-IO/unstructured-ingest/tree/main/example-docs) folder in the [Unstructured-IO/unstructured-ingest](https://github.com/Unstructured-IO/unstructured-ingest) repository in GitHub.\n",
        "\n",
        "[Learn how to verify these requirements for S3](https://docs.unstructured.io/api-reference/workflow/sources/s3). At the end of that webpage, ignore the section titled \"To create the source connector,\" as you will do that later in this notebook instead.\n",
        "\n",
        "You will also need, for Snowflake:\n",
        "\n",
        "1. A Snowflake account and your account's identifier.\n",
        "2. Your user's login name (not username) and password in your Snowflake account.\n",
        "3. The names of the target catalog, schema, table, and warehouse in your Snowflake account.\n",
        "\n",
        "   **IMPORTANT!** Your table must have a column named `embeddings` with a datatype of `VECTOR(FLOAT, 1024)` to work with this notebook.\n",
        "   \n",
        "4. The name of the Snowflake role that your user belongs to and that also has sufficient access to the target catalog, schema, table, and warehouse.\n",
        "5. The hostname and port number for the host, and the name of the warehouse.\n",
        "\n",
        "[Learn how to verify these requirements for Snowflake](https://docs.unstructured.io/api-reference/workflow/destinations/snowflake). At the end of that webpage, ignore the section titled \"To create the destination connector,\" as you will do that later in this notebook instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQQE2xbgls1i"
      },
      "source": [
        "# Step 1: Load dependencies, set initial imports and environment variables, and define a helper function\n",
        "\n",
        "Run the following cell to load code dependencies for the Unstructured API and for using date/time information to generate unique names for your Unstructured connectors and workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3c1FNAlT-it",
        "outputId": "2d00aeb3-c83b-40b4-8b80-47b34c72d9cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting unstructured-client\n",
            "  Downloading unstructured_client-0.34.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting datetime\n",
            "  Downloading DateTime-5.5-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting aiofiles>=24.1.0 (from unstructured-client)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.11/dist-packages (from unstructured-client) (43.0.3)\n",
            "Collecting eval-type-backport>=0.2.0 (from unstructured-client)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client) (1.6.0)\n",
            "Requirement already satisfied: pydantic>=2.11.2 in /usr/local/lib/python3.11/dist-packages (from unstructured-client) (2.11.4)\n",
            "Collecting pypdf>=4.0 (from unstructured-client)\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client) (1.0.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client) (0.4.0)\n",
            "Collecting zope.interface (from datetime)\n",
            "  Downloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m270.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from datetime) (2025.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.1->unstructured-client) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.2->unstructured-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.2->unstructured-client) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.2->unstructured-client) (4.13.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from requests-toolbelt>=1.0.0->unstructured-client) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from zope.interface->datetime) (75.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.1->requests-toolbelt>=1.0.0->unstructured-client) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.1->requests-toolbelt>=1.0.0->unstructured-client) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->unstructured-client) (1.3.1)\n",
            "Downloading unstructured_client-0.34.0-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.4/189.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DateTime-5.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.8/259.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: zope.interface, pypdf, eval-type-backport, aiofiles, datetime, unstructured-client\n",
            "Successfully installed aiofiles-24.1.0 datetime-5.5 eval-type-backport-0.2.2 pypdf-5.4.0 unstructured-client-0.34.0 zope.interface-7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U unstructured-client datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC6HThFGo2UW"
      },
      "source": [
        "Run the following cell to set imports for setting and getting environment variables, calling the Unstructured API, and using date/time functions. Also declare a helper function to make it easier to read JSON-formatted payloads that are returned by calls to the Unstructured API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL8WpI79UtaG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from unstructured_client import UnstructuredClient\n",
        "from datetime import datetime\n",
        "\n",
        "def pretty_print_model(response_model):\n",
        "    print(response_model.model_dump_json(indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAlDleNpoFTh"
      },
      "source": [
        "Set the following environment variables' values, as described in the following code comments, and then run the cell. In this notebook, you set these environment variables directly, for convenience. In production, you would typically set these environment variables separately from your code, to lessen the risk of exposing sensitive information such as access keys and passwords to other users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kzo9QAI3mNDL"
      },
      "outputs": [],
      "source": [
        "os.environ[\"AWS_S3_URL\"] = \"...\" # The path to the S3 bucket or folder, formatted as s3://my-bucket/ (if the files are in the bucket’s root) or s3://my-bucket/my-folder/.\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"...\" # The AWS access key ID for the authenticated AWS IAM user.\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"...\" # The corresponding AWS secret access key.\n",
        "os.environ[\"SNOWFLAKE_ACCOUNT\"] =\"...\" # The ID of the target Snowflake account. *\n",
        "os.environ[\"SNOWFLAKE_USER\"] = \"...\" # The login name (not username) of the target Snowflake user in the account. *\n",
        "os.environ[\"SNOWFLAKE_PASSWORD\"] = \"...\" # The user's password. *\n",
        "os.environ[\"SNOWFLAKE_ROLE\"] = \"...\" # The name of the target role for the user. This role must have appropriate permissions to the target database, schema, table, and warehouse.\n",
        "os.environ[\"SNOWFLAKE_HOST\"] = \"...\" # The hostname for the target Snowflake warehouse.\n",
        "os.environ[\"SNOWFLAKE_PORT\"] = \"443\" # The warehouse's port number.\n",
        "os.environ[\"SNOWFLAKE_WAREHOUSE\"] = \"COMPUTE_WH\" # The name of the target Snowflake warehouse. *\n",
        "os.environ[\"SNOWFLAKE_DATABASE\"] = \"...\" # The name of the target Snowflake database. *\n",
        "os.environ[\"SNOWFLAKE_SCHEMA\"] = \"...\" # The name of the target namespace (also known as a schema) in the database. *\n",
        "os.environ[\"SNOWFLAKE_TABLE\"] = \"ELEMENTS\" # The name of the target table in the schema. Typically, this table is named ELEMENTS.\n",
        "os.environ[\"SNOWFLAKE_RECORD_ID_KEY\"] = \"RECORD_ID\" # The name of the column in the table that uniquely identifies each record. Typically, this column is named RECORD_ID.\n",
        "os.environ[\"UNSTRUCTURED_API_KEY\"] = \"...\" # Your Unstructured API key."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjmrypmpnBIE"
      },
      "source": [
        "# Step 2: Create the source connector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV18KFJFrfCq"
      },
      "source": [
        "Run the following cell to create the source connection to the Amazon S3 bucket. If successful, Unstructured prints information about the newly created source connector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmqICLS4VCtw"
      },
      "outputs": [],
      "source": [
        "from unstructured_client.models.operations import CreateSourceRequest\n",
        "from unstructured_client.models.shared import (\n",
        "    CreateSourceConnector,\n",
        "    SourceConnectorType,\n",
        "    S3SourceConnectorConfigInput\n",
        ")\n",
        "\n",
        "unique_source_connector_suffix = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "\n",
        "with UnstructuredClient(api_key_auth=os.getenv(\"UNSTRUCTURED_API_KEY\")) as client:\n",
        "    response = client.sources.create_source(\n",
        "        request=CreateSourceRequest(\n",
        "            create_source_connector=CreateSourceConnector(\n",
        "                name=f\"s3-source-{unique_source_connector_suffix}\",\n",
        "                type=SourceConnectorType.S3,\n",
        "                config=S3SourceConnectorConfigInput(\n",
        "                    remote_url=os.getenv(\"AWS_S3_URL\"),\n",
        "                    key=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
        "                    secret=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    source_connector_id = response.source_connector_information.id\n",
        "    pretty_print_model(response.source_connector_information)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ2Q2jDp2oUf"
      },
      "source": [
        "## Step 3: Create the destination connector\n",
        "\n",
        "Run the following cell to create the destination connection to the Snowflake table. If successful, Unstructured prints information about the newly created destination connector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVkK2NCmV4pN"
      },
      "outputs": [],
      "source": [
        "from unstructured_client.models.operations import CreateDestinationRequest\n",
        "from unstructured_client.models.shared import (\n",
        "    CreateDestinationConnector,\n",
        "    DestinationConnectorType,\n",
        "    SnowflakeDestinationConnectorConfigInput\n",
        ")\n",
        "\n",
        "unique_destination_connector_suffix = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "\n",
        "with UnstructuredClient(api_key_auth=os.getenv(\"UNSTRUCTURED_API_KEY\")) as client:\n",
        "    response = client.destinations.create_destination(\n",
        "        request=CreateDestinationRequest(\n",
        "            create_destination_connector=CreateDestinationConnector(\n",
        "                name=f\"snowflake-destination-{unique_destination_connector_suffix}\",\n",
        "                type=DestinationConnectorType.SNOWFLAKE,\n",
        "                config=SnowflakeDestinationConnectorConfigInput(\n",
        "                    account=os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
        "                    user=os.getenv(\"SNOWFLAKE_USER\"),\n",
        "                    password=os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
        "                    role=os.getenv(\"SNOWFLAKE_ROLE\"),\n",
        "                    host=os.getenv(\"SNOWFLAKE_HOST\"),\n",
        "                    port=os.getenv(\"SNOWFLAKE_PORT\"),\n",
        "                    database=os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
        "                    schema=os.getenv(\"SNOWFLAKE_SCHEMA\"),\n",
        "                    table_name=os.getenv(\"SNOWFLAKE_TABLE\"),\n",
        "                    record_id_key=os.getenv(\"SNOWFLAKE_RECORD_ID_KEY\")\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    destination_connector_id = response.destination_connector_information.id\n",
        "    pretty_print_model(response.destination_connector_information)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1pDmMDd2xYS"
      },
      "source": [
        "## Step 4: Create the workflow\n",
        "\n",
        "Run the following cell to create the workflow. This workflow uses Claude Sonnet 4.5, a vision language model (VLM), to translate the documents' contents into Unstructured document elements. The elements' text is then chunked into smaller parts for easier use by RAG search.\n",
        "\n",
        "If the cell runs successfully, Unstructured prints information about the newly created workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJoUoeDNcIoR"
      },
      "outputs": [],
      "source": [
        "from unstructured_client.models.operations import CreateWorkflowRequest\n",
        "from unstructured_client.models.shared import (\n",
        "    WorkflowNode,\n",
        "    CreateWorkflow,\n",
        "    WorkflowType\n",
        ")\n",
        "\n",
        "# Partition the content by using a vision language model (VLM).\n",
        "partition_node = WorkflowNode(\n",
        "    name=\"Partitioner\",\n",
        "    subtype=\"vlm\",\n",
        "    type=\"partition\",\n",
        "    settings={\n",
        "        \"provider\": \"anthropic\",\n",
        "        \"provider_api_key\": None,\n",
        "        \"model\": \"claude-sonnet-4-5-20250929\",\n",
        "        \"output_format\": \"text/html\",\n",
        "        \"user_prompt\": None,\n",
        "        \"format_html\": True,\n",
        "        \"unique_element_ids\": True,\n",
        "        \"is_dynamic\": True,\n",
        "        \"allow_fast\": True\n",
        "    }\n",
        ")\n",
        "\n",
        "# Chunk the partitioned content.\n",
        "chunk_node = WorkflowNode(\n",
        "    name=\"Chunker\",\n",
        "    subtype=\"chunk_by_title\",\n",
        "    type=\"chunk\",\n",
        "    settings={\n",
        "        \"unstructured_api_url\": None,\n",
        "        \"unstructured_api_key\": None,\n",
        "        \"multipage_sections\": False,\n",
        "        \"combine_text_under_n_chars\": 0,\n",
        "        \"include_orig_elements\": True,\n",
        "        \"new_after_n_chars\": 1500,\n",
        "        \"max_characters\": 2048,\n",
        "        \"overlap\": 160,\n",
        "        \"overlap_all\": False,\n",
        "        \"contextual_chunking_strategy\": None\n",
        "    }\n",
        ")\n",
        "\n",
        "unique_workflow_suffix = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "\n",
        "with UnstructuredClient(api_key_auth=os.getenv(\"UNSTRUCTURED_API_KEY\")) as client:\n",
        "    response = client.workflows.create_workflow(\n",
        "        request=CreateWorkflowRequest(\n",
        "            create_workflow=CreateWorkflow(\n",
        "                name=f\"s3-to-snowflake-custom-workflow-{unique_workflow_suffix}\",\n",
        "                source_id=source_connector_id,\n",
        "                destination_id=destination_connector_id,\n",
        "                workflow_type=WorkflowType.CUSTOM,\n",
        "                workflow_nodes=[\n",
        "                    partition_node,\n",
        "                    chunk_node\n",
        "                ],\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    workflow_id = response.workflow_information.id\n",
        "    pretty_print_model(response.workflow_information)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVCzW_mO20Na"
      },
      "source": [
        "## Step 5: Run the workflow\n",
        "\n",
        "Run the following cell to start running the workflow. Unstructured will begin processing the files in the S3 bucket, sending the processed data into the Snowflake table. If successful, Unstructured prints information about the workflow that is running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V23w1I77CB1y"
      },
      "outputs": [],
      "source": [
        "from unstructured_client.models.operations import RunWorkflowRequest\n",
        "\n",
        "with UnstructuredClient(api_key_auth=os.getenv(\"UNSTRUCTURED_API_KEY\")) as client:\n",
        "    response = client.workflows.run_workflow(\n",
        "        request=RunWorkflowRequest(\n",
        "            workflow_id=workflow_id,\n",
        "        )\n",
        "    )\n",
        "\n",
        "pretty_print_model(response.job_information)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9a1cC1XnSmf"
      },
      "source": [
        "# Step 6: Get the workflow run's job ID\n",
        "\n",
        "Run the following cell to get the workflow run's job ID, which is needed to poll for job completion later. If successful, Unstructured prints the job's ID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqyjrFwACi7b"
      },
      "outputs": [],
      "source": [
        "from unstructured_client.models.operations import ListJobsRequest\n",
        "\n",
        "with UnstructuredClient(api_key_auth=os.getenv(\"UNSTRUCTURED_API_KEY\")) as client:\n",
        "    response = client.jobs.list_jobs(\n",
        "        request=ListJobsRequest(\n",
        "            workflow_id=workflow_id\n",
        "        )\n",
        ")\n",
        "\n",
        "last_job = response.response_list_jobs[0]\n",
        "job_id = last_job.id\n",
        "print(f\"job_id: {job_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7GzuusCnWmr"
      },
      "source": [
        "# Step 7: Poll for job completion\n",
        "\n",
        "Run the following cell to confirm the job has finished running. If successful, Unstructured prints \"status\": \"COMPLETED\" within the information about the job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMxN5njjC4vH"
      },
      "outputs": [],
      "source": [
        "from unstructured_client.models.operations import GetJobRequest\n",
        "import time\n",
        "\n",
        "def poll_job_status(job_id):\n",
        "    while True:\n",
        "        with UnstructuredClient(api_key_auth=os.getenv(\"UNSTRUCTURED_API_KEY\")) as client:\n",
        "          response = client.jobs.get_job(\n",
        "            request=GetJobRequest(\n",
        "                job_id=job_id\n",
        "            )\n",
        "        )\n",
        "\n",
        "        job = response.job_information\n",
        "\n",
        "        if job.status == \"SCHEDULED\":\n",
        "            print(\"Job is scheduled, polling again in 10 seconds...\")\n",
        "            time.sleep(10)\n",
        "        elif job.status == \"IN_PROGRESS\":\n",
        "            print(\"Job is in progress, polling again in 10 seconds...\")\n",
        "            time.sleep(10)\n",
        "        else:\n",
        "            print(\"Job is completed\")\n",
        "            break\n",
        "\n",
        "    return job\n",
        "\n",
        "job = poll_job_status(job_id)\n",
        "pretty_print_model(job)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10fZ_SaL3IA0"
      },
      "source": [
        "## Step 8: Connect to Snowflake\n",
        "\n",
        "Run the following cell to install code dependencies for connecting to Snowflake.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcJPF1Q0os6x"
      },
      "outputs": [],
      "source": [
        "!pip install snowflake-connector-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sTvgnDrvAej"
      },
      "source": [
        "Run the following cell to connect to Snowflake."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaeoYEl3Jke5"
      },
      "outputs": [],
      "source": [
        "import snowflake.connector\n",
        "\n",
        "config = {\n",
        "    \"user\": os.getenv(\"SNOWFLAKE_USER\"),\n",
        "    \"password\": os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
        "    \"account\": os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
        "    \"warehouse\": os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n",
        "    \"database\": os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
        "    \"schema\": os.getenv(\"SNOWFLAKE_SCHEMA\")\n",
        "}\n",
        "\n",
        "try:\n",
        "    conn = snowflake.connector.connect(**config)\n",
        "    print(\"Connection established successfully.\")\n",
        "except snowflake.connector.Error as e:\n",
        "    print(f\"Connection failed: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JXm2-8ynjeh"
      },
      "source": [
        "# Step 9: Generate embedding vectors for the table's text contents\n",
        "\n",
        "Run the following cell to generate embedding vectors for the text contents of each of the table's rows. If successful, the number of table rows that had embedding vectors generated for them is returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFFkIEFFKn12"
      },
      "outputs": [],
      "source": [
        "cursor = conn.cursor()\n",
        "table = os.getenv(\"SNOWFLAKE_TABLE\")\n",
        "query = f\"UPDATE {table} SET embeddings = SNOWFLAKE.CORTEX.EMBED_TEXT_1024('voyage-multilingual-2', text)\"\n",
        "\n",
        "cursor.execute(query)\n",
        "\n",
        "print(f\"Rows updated: {cursor.rowcount}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeVB5Wr6nqJU"
      },
      "source": [
        "# Step 10: Generate embedding vectors for the natural-language query\n",
        "\n",
        "In the following cell, specify the query you want to use, and then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWgXv5SAvyfO"
      },
      "outputs": [],
      "source": [
        "natural_language_query = \"In what year were women given the right to vote in the United States?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7azlbmeNwIv4"
      },
      "source": [
        "Run the following cell to create a table named `query_table` in the same schema as your target table, if `query_table` does not already exist there. Embedding vectors will then be generated for your natural-language query and put into the new or existing `query_table` table. If successful, \"Rows inserted: 1\" is returned.\n",
        "\n",
        "If you change the natural-language query in the preceding cell, you must run the following cell again, to make sure that matching embedding vectors are generated and overwrite the previous ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LG7wkjZN_4i"
      },
      "outputs": [],
      "source": [
        "cursor.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE query_table (\n",
        "        query_vec VECTOR(FLOAT, 1024)\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "cursor.execute(\"\"\"\n",
        "    INSERT INTO query_table\n",
        "    SELECT SNOWFLAKE.CORTEX.EMBED_TEXT_1024(\n",
        "        'voyage-multilingual-2',\n",
        "        %s\n",
        "    )\n",
        "\"\"\", (natural_language_query,))\n",
        "\n",
        "print(f\"Rows inserted: {cursor.rowcount}\")\n",
        "\n",
        "conn.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCCbyTDpnyeG"
      },
      "source": [
        "# Step 11: Perform RAG search\n",
        "\n",
        "Run the following cell to perform a vector cosine similarity operation, looking for the row in the target table that has the closest similarity to your natural-language query. Based on that row's text, use the Mistral 7B model to return and print a natural-language reply to your query.\n",
        "\n",
        "To search again with a different natural-language query, go back to Step 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9TCNPJFNp9x"
      },
      "outputs": [],
      "source": [
        "from textwrap import fill\n",
        "\n",
        "query = f\"\"\"\n",
        "WITH result AS (\n",
        "    SELECT\n",
        "        t.text,\n",
        "        %s AS query_text,\n",
        "        VECTOR_COSINE_SIMILARITY(t.embeddings, q.query_vec) AS similarity\n",
        "    FROM {table} t, query_table q\n",
        "    ORDER BY similarity DESC\n",
        "    LIMIT 1\n",
        ")\n",
        "SELECT SNOWFLAKE.CORTEX.COMPLETE(\n",
        "    'mistral-7b',\n",
        "    CONCAT('Answer this question: ', query_text, ' using this text: ', text)\n",
        ") AS answer\n",
        "FROM result;\n",
        "\"\"\"\n",
        "\n",
        "cursor.execute(query, (natural_language_query,))\n",
        "result = cursor.fetchall()[0][0]\n",
        "print(fill(result, width=80))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn5W6WFXLtIo"
      },
      "source": [
        "## Optional: Use additional Snowflake Cortex functions\n",
        "\n",
        "You can run the following cells to experiment with the following functions against your Snowflake table:\n",
        "\n",
        "- [ENTITY_SENTIMENT](https://docs.snowflake.com/user-guide/snowflake-cortex/sentiment#label-sentiment-entity-sentiment), which returns sentiment scores for English-language text, including overall sentiment and specific sentiment for specified entities.\n",
        "- [SENTIMENT](https://docs.snowflake.com/user-guide/snowflake-cortex/sentiment#sentiment), which returns an overall sentiment score for the given English-language input text.\n",
        "- [EXTRACT_ANSWER](https://docs.snowflake.com/sql-reference/functions/extract_answer-snowflake-cortex), which extracts an answer to a given question from text.\n",
        "- [SUMMARIZE](https://docs.snowflake.com/sql-reference/functions/summarize-snowflake-cortex), which summarizes the given English-language input text.\n",
        "- [TRANSLATE](https://docs.snowflake.com/sql-reference/functions/translate-snowflake-cortex), which translates the given input text from one supported language to another.\n",
        "- [CLASSIFY_TEXT](https://docs.snowflake.com/sql-reference/functions/classify_text-snowflake-cortex), which classifies free-form text into categories that you provide."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elV9w6t5MuQo"
      },
      "source": [
        "### ENTITY_SENTIMENT\n",
        "\n",
        "Run the following cell to perform sentiment analysis on the contents of the `text` column for the first 10 rows of your table.\n",
        "\n",
        "To change the sentiment labels to analyze, replace `['Prescriptive', 'Declarative']` with up to 10 of your own labels. Each label may not exceed 30 characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwbnNdAfNaGp"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "cursor = conn.cursor()\n",
        "table = os.getenv(\"SNOWFLAKE_TABLE\")\n",
        "\n",
        "query = f\"\"\"\n",
        "SELECT SNOWFLAKE.CORTEX.ENTITY_SENTIMENT(\n",
        "    text,\n",
        "    ['Prescriptive', 'Declarative']\n",
        "), text FROM {table} LIMIT 10;\n",
        "\"\"\"\n",
        "\n",
        "cursor.execute(query)\n",
        "result = cursor.fetchall()\n",
        "for entry in result:\n",
        "    # Print the text part.\n",
        "    print(\"Text:\\n\")\n",
        "    print(entry[1])\n",
        "    # Pretty-print the JSON-formatted sentiment analysis part.\n",
        "    print('-' * 80)  # Add a separator for clarity,\n",
        "    print(\"\\nSentiment analysis:\\n\")\n",
        "    parsed_json = json.loads(entry[0])\n",
        "    print(json.dumps(parsed_json, indent=4))\n",
        "    print('=' * 80)  # Add a separator for clarity, before printing the next item."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdNGdhyLMxx0"
      },
      "source": [
        "### SENTIMENT\n",
        "\n",
        "Run the following cell to return an overall sentiment score for the `text` column for the first 10 rows of your table.\n",
        "\n",
        "Sentiment scores are expressed as a floating-point number from -1 to 1 (inclusive) indicating the level of negative or positive sentiment in the text. Values around 0 indicate neutral sentiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7xnmLoNbCD6"
      },
      "outputs": [],
      "source": [
        "query = f\"\"\"\n",
        "SELECT SNOWFLAKE.CORTEX.SENTIMENT(\n",
        "    text\n",
        "), text FROM {table} LIMIT 10;\n",
        "\"\"\"\n",
        "\n",
        "cursor.execute(query)\n",
        "result = cursor.fetchall()\n",
        "print(json.dumps(result, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKdhEsQhM0ki"
      },
      "source": [
        "### EXTRACT_ANSWER\n",
        "\n",
        "Run the following cell to return the answer to a question about the `text` column for the first 10 rows of your table.\n",
        "\n",
        "To ask a different question, change the value of the following `question` variable, and run the cell again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6eRfGj2vTgg"
      },
      "outputs": [],
      "source": [
        "question = \"Who is primarily mentioned in this text?\"\n",
        "\n",
        "query = f\"\"\"\n",
        "SELECT SNOWFLAKE.CORTEX.EXTRACT_ANSWER(text, '{question}'), text FROM {table}  LIMIT 10;\n",
        "\"\"\"\n",
        "\n",
        "cursor.execute(query)\n",
        "result = cursor.fetchall()\n",
        "for entry in result:\n",
        "    # Print the text part.\n",
        "    print(\"Text:\\n\")\n",
        "    print(entry[1])\n",
        "    # Pretty-print the JSON-formatted answer part.\n",
        "    print('-' * 80)  # Add a separator for clarity.\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Answer:\")\n",
        "    parsed_json = json.loads(entry[0])\n",
        "    print(json.dumps(parsed_json, indent=4))\n",
        "    print('=' * 80)  # Add a separator for clarity, before printing the next item."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVy_uV-2M4f-"
      },
      "source": [
        "### SUMMARIZE\n",
        "\n",
        "Run the following cell to return a summary of the `text` column for the first 10 rows of your table.\n",
        "\n",
        "The `text` column must contain English text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lwesK1ex-MC"
      },
      "outputs": [],
      "source": [
        "query = f\"\"\"\n",
        "SELECT SNOWFLAKE.CORTEX.SUMMARIZE(text), text FROM {table}  LIMIT 10;\n",
        "\"\"\"\n",
        "\n",
        "cursor.execute(query)\n",
        "result = cursor.fetchall()\n",
        "for entry in result:\n",
        "    print(\"Original text:\\n\")\n",
        "    print(entry[1])\n",
        "    print('-' * 80) # Add a separator for clarity.\n",
        "    print(\"Summary text:\\n\")\n",
        "    print(entry[0])\n",
        "    print('=' * 80) # Add a separator for clarity, before printing the next item."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP_2ir4_M8Zs"
      },
      "source": [
        "### TRANSLATE\n",
        "\n",
        "Run the following cell to return a language translation of the `text` column for the first 10 rows of your table.\n",
        "\n",
        "Over a dozen languages are supported. For the full list of supported languages, see the [TRANSLATE](https://docs.snowflake.com/sql-reference/functions/translate-snowflake-cortex) documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VDfPXdWzOUJ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "cursor = conn.cursor()\n",
        "table = os.getenv(\"SNOWFLAKE_TABLE\")\n",
        "\n",
        "query = f\"\"\"\n",
        "SELECT SNOWFLAKE.CORTEX.TRANSLATE(text, 'en', 'es'), text FROM {table}  LIMIT 10;\n",
        "\"\"\"\n",
        "\n",
        "cursor.execute(query)\n",
        "result = cursor.fetchall()\n",
        "for entry in result:\n",
        "    print(\"Original English text:\\n\")\n",
        "    print(entry[1])\n",
        "    print('-' * 80) # Add a separator for clarity.\n",
        "    print(\"Text translated into Spanish:\\n\")\n",
        "    print(entry[0])\n",
        "    print('=' * 80) # Add a separator for clarity, before printing the next item."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ-GnPFbM_hg"
      },
      "source": [
        "### CLASSIFY_TEXT\n",
        "\n",
        "Run the following cell to perform text classification on the contents of the `text` column for the first 10 rows of your table.\n",
        "\n",
        "To change the text classification labels to use, replace `['Section', 'Article', 'Amendment', 'Other']` with between 2 and 100 of your own labels, inclusive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RY9TyYDSzmUh"
      },
      "outputs": [],
      "source": [
        "query = f\"\"\"\n",
        "SELECT SNOWFLAKE.CORTEX.CLASSIFY_TEXT(\n",
        "  text,\n",
        "  ['Section', 'Article', 'Amendment', 'Other']\n",
        "), text FROM {table} LIMIT 10;\n",
        "\"\"\"\n",
        "\n",
        "cursor.execute(query)\n",
        "result = cursor.fetchall()\n",
        "for entry in result:\n",
        "    print(\"Text:\\n\")\n",
        "    print(entry[1])\n",
        "    print('-' * 80) # Add a separator for clarity.\n",
        "    print(\"Classification:\\n\")\n",
        "    parsed_json = json.loads(entry[0])\n",
        "    print(json.dumps(parsed_json, indent=4))\n",
        "    print('=' * 80) # Add a separator for clarity, before printing the next item."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vclUsNQU3R2s"
      },
      "source": [
        "## Additional Resources\n",
        "\n",
        "- [Unstructured user interface (UI) documentation](https://docs.unstructured.io/ui/overview)\n",
        "- [Unstructured Workflow Endpoint API documentation](https://docs.unstructured.io/api-reference/workflow/workflows)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
