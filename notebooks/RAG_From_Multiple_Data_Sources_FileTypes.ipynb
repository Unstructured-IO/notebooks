{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Everything (from) Everywhere All at Once - Rag from Multiple Data Sources and Multiple File Types\n",
        "\n",
        "This notebook is complementary to [this blog post](https://unstructured.io/blog/everything-from-everywhere-all-at-once-enterprise-rag-with-multiple-sources-and-filetypes). The blog walks through setting up Unstructured connectors, building the preprocessing workflow, and getting your data from Azure Blob Storage, OneDrive, and Outlook into Astra DB.\n",
        "\n",
        "At this point, if you've followed the previous sections from the blog, you now have a fully functioning Unstructured pipeline that connects to your enterprise data — Outlook threads, OneDrive decks, Azure-stored PDFs — and processes them into clean, enriched, and embedded chunks inside AstraDB.\n",
        "\n",
        "Now it’s time to switch gears and make that data useful.\n",
        "\n",
        "We're going to set up a simple RAG pipeline using LangChain that can query the processed content stored in AstraDB. The goal is to retrieve relevant context across emails, slides, contracts, and pass it to an LLM to generate grounded answers.\n",
        "\n",
        "Let’s start with some lightweight setup:"
      ],
      "metadata": {
        "id": "yo-G0xgwJ9Nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q astrapy openai langchain langchain-openai langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzWOTjit3Rus",
        "outputId": "5133085c-087c-4291-a20a-4fce999680d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/333.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.5/333.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from astrapy import DataAPIClient\n",
        "from openai import OpenAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n"
      ],
      "metadata": {
        "id": "_-3nmQdQ3kNM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connecting to AstraDB and Setting Up Your Models\n"
      ],
      "metadata": {
        "id": "60I_55kSDuWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With our Unstructured pipeline already pushing enriched content into AstraDB, the next step is to connect our notebook to that vector store and configure the models we’ll use for retrieval and generation.\n",
        "\n",
        "First, load your credentials from Colab Secrets and establish the AstraDB and OpenAI clients:"
      ],
      "metadata": {
        "id": "hZb7GHSVDenz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['ASTRA_DB_API_ENDPOINT'] = userdata.get('ASTRA_DB_API_ENDPOINT')\n",
        "os.environ['ASTRA_DB_APPLICATION_TOKEN'] = userdata.get('ASTRA_DB_APPLICATION_TOKEN')\n",
        "os.environ['ASTRA_DB_COLLECTION_NAME'] = userdata.get('ASTRA_DB_COLLECTION_NAME')\n",
        "os.environ['ASTRA_DB_KEYSPACE'] = userdata.get('ASTRA_DB_KEYSPACE')\n"
      ],
      "metadata": {
        "id": "99PX79p8_gXh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "NwqQRZhH_hxH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "astradb_client = DataAPIClient(os.environ[\"ASTRA_DB_APPLICATION_TOKEN\"])\n",
        "database = astradb_client.get_database(os.environ[\"ASTRA_DB_API_ENDPOINT\"])\n",
        "COLLECTION = database.get_collection(\n",
        "    name=os.environ[\"ASTRA_DB_COLLECTION_NAME\"],\n",
        "    keyspace=os.environ[\"ASTRA_DB_KEYSPACE\"]\n",
        ")\n",
        "\n",
        "EMBEDDING_MODEL = \"text-embedding-3-large\"\n",
        "LLM_MODEL = \"gpt-4o\"\n",
        "TOP_K = 5\n"
      ],
      "metadata": {
        "id": "FS2iuDeQ3eUE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a Simple Retriever\n",
        "\n",
        "Let’s wire up a lightweight retrieval function that runs a semantic similarity search over your AstraDB collection using OpenAI’s latest `text-embedding-3-large` model.\n",
        "\n",
        "We’ll define two things:\n",
        "\n",
        "- A helper to embed queries\n",
        "- An `enhanced_retriever` that pulls relevant content and shows which files it came from\n"
      ],
      "metadata": {
        "id": "gkUjpiZLDx-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(text: str):\n",
        "    \"\"\"Generate embedding using OpenAI's text-embedding-3-large model\"\"\"\n",
        "    response = openai_client.embeddings.create(\n",
        "        model=EMBEDDING_MODEL,\n",
        "        input=text\n",
        "    )\n",
        "    return response.data[0].embedding\n",
        "\n",
        "\n",
        "def enhanced_retriever(query: str, n: int = TOP_K) -> dict:\n",
        "    \"\"\"Enhanced retriever that returns documents with metadata\"\"\"\n",
        "    embedding = get_embedding(query)\n",
        "    results = COLLECTION.find(sort={\"$vector\": embedding}, limit=n)\n",
        "\n",
        "    retrieved_docs = []\n",
        "    for doc in results:\n",
        "        # import pdb; pdb.set_trace()\n",
        "        retrieved_docs.append({\n",
        "            \"content\": doc.get(\"content\", \"\"),\n",
        "            \"source\": doc[\"metadata\"][\"metadata\"][\"filename\"]\n",
        "        })\n",
        "\n",
        "    sources = set([d[\"source\"] for d in retrieved_docs])\n",
        "    print(f\"Retrieved from: {', '.join(sources)}\")\n",
        "\n",
        "    context = \"\\n\".join(f\"[Source: {d['source']}]\\n{d['content']}\" for d in retrieved_docs)\n",
        "    return context"
      ],
      "metadata": {
        "id": "vfd9Sc4-3xpU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Up the LLM and Running the RAG Chain\n",
        "\n",
        "With the retriever in place, we can now hook it up to a large language model using a simple LangChain prompt template. This is where the final response gets crafted while being grounded in the enterprise data we pulled from AstraDB.\n",
        "\n",
        "We’ll use `ChatOpenAI` with a light temperature and a prompt that encourages synthesis across multiple sources:\n"
      ],
      "metadata": {
        "id": "PGiw1ZbtD9Mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(\n",
        "    model_name=LLM_MODEL,\n",
        "    temperature=0.3,\n",
        "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
        ")\n",
        "\n",
        "prompt_template = \"\"\"You are an AI assistant with access to multiple enterprise documents including financial reports,\n",
        "inventory data, business presentations, and customer communications.\n",
        "\n",
        "Use the following context to answer the question. If the answer requires data from multiple sources,\n",
        "synthesize the information appropriately.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Please provide a comprehensive answer based on the available information. If specific numbers or data points\n",
        "are mentioned in the context, include them in your response.\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template,\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "uyNmwykM4Hln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "def create_rag_chain():\n",
        "    return LLMChain(llm=llm, prompt=PROMPT)\n",
        "\n",
        "rag_chain = create_rag_chain()\n",
        "\n",
        "def ask_question(question: str):\n",
        "    \"\"\"Main function to ask questions against the RAG system\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\" Question: {question}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    context = enhanced_retriever(question)\n",
        "\n",
        "    response = rag_chain.invoke({\n",
        "        \"context\": context,\n",
        "        \"question\": question\n",
        "    })\n",
        "\n",
        "    print(f\"\\n Answer:\\n{response['text']}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "W0loZwLR51G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When ask questions like the ones below, here’s what’s really happening behind the scenes:\n",
        "\n",
        "- **Your question is embedded** using OpenAI’s `text-embedding-3-large` model.\n",
        "- **AstraDB vector search retrieves the top chunks** of content most relevant to your query.\n",
        "- Those chunks can come from **anywhere** — a PDF financial report, an Outlook email, or a PowerPoint slide deck and the retriever tags each one with its original source.\n",
        "- **The LLM synthesizes the answer**, combining numbers, names, and context from multiple files into one grounded response.\n",
        "\n",
        "This is why you see outputs such as:\n",
        "\n",
        "- **Q3 Revenue** pulled directly from a PDF financial report  \n",
        "- **Customer complaints** summarized from an Outlook email  \n",
        "- **Hiring plans** extracted from both a PowerPoint deck and a PDF report  \n",
        "\n",
        "All automatically with no extra work on your part."
      ],
      "metadata": {
        "id": "4SwBpnlZE-UI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ask_question(\"What was TechVision's total revenue in Q3 2024?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbdFejQW5VLZ",
        "outputId": "c2371cb6-5e97-4737-f1bb-34c6c92f3fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " Question: What was TechVision's total revenue in Q3 2024?\n",
            "================================================================================\n",
            "Retrieved from: Q3 2024 Financial Report - TechVision Industries.pdf\n",
            "\n",
            " Answer:\n",
            "TechVision Industries' total revenue in Q3 2024 was $847.3 million. This figure represents a 23% year-over-year growth compared to the same period in 2023. The revenue growth was driven by strong performance across various business segments, including a notable 41% increase in recurring revenue from the cloud services division.\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The magic here is that Unstructured doesn’t treat each file type differently at retrieval time.  \n",
        "Instead, it converts every incoming file — PDF, PowerPoint, Excel, email — into a **unified document model** of structured elements enriched with metadata.\n",
        "\n",
        "Each element carries:\n",
        "- Its **type** (text, table, image),\n",
        "- The **source filename**,\n",
        "- Any **enrichments** like image captions or table descriptions,\n",
        "- And its **position** within the original document.\n",
        "\n",
        "Because of this standardization, your retrieval pipeline only has to work with one consistent format, even though the underlying data spans multiple systems and file types.\n",
        "\n"
      ],
      "metadata": {
        "id": "r9dr3U2-FKrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ask_question(\"What are Jennifer Martinez's main complaints about support?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4gkJ2q76IvL",
        "outputId": "a83170ef-2019-40b6-f7ae-439a5ac074a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " Question: What are Jennifer Martinez's main complaints about support?\n",
            "================================================================================\n",
            "Retrieved from: 98729709ec5679da.eml\n",
            "\n",
            " Answer:\n",
            "Jennifer Martinez, the VP of Information Technology at Global Finance Corp, has several main complaints about the support received from TechVision for their CloudSync Pro Enterprise product:\n",
            "\n",
            "1. **Lack of Communication**: Jennifer is extremely concerned about the lack of communication regarding known issues with version 3.2.1. She notes that similar complaints have been observed on community forums since September 28, yet no advisory was issued to enterprise customers, which she finds unacceptable.\n",
            "\n",
            "2. **Delayed Response**: There has been a significant delay in response to their support case (#CS-2024-10-08-4573), with no response received for 72 hours after opening the case. This delay is critical given the severity of the issues they are experiencing.\n",
            "\n",
            "3. **System Instability and Impact**: The issues with CloudSync Pro Enterprise are causing significant operational disruptions at Global Finance Corp, including putting three critical projects on hold and resulting in complaints from two major clients about delayed deliverables.\n",
            "\n",
            "4. **Technical Issues**: Jennifer outlines several technical issues that require immediate attention, including synchronization failures, the need for an emergency patch or hotfix for version 3.2.1, performance tuning recommendations, data recovery assistance for corrupted files, and a detailed review of their configuration and architecture.\n",
            "\n",
            "5. **Escalation and Severity**: This is the first time in seven years of being a loyal customer with over $3.2M in annual licensing that Global Finance Corp has had to escalate issues to this level, indicating the severity of the situation.\n",
            "\n",
            "6. **Required Assistance**: Jennifer lists specific assistance needed, including a remote session with a Tier 3 support engineer, root cause analysis, and potentially on-site support if remote resolution is not possible within 24 hours.\n",
            "\n",
            "Overall, Jennifer's main complaints revolve around inadequate communication, delayed support response, and the critical impact of unresolved technical issues on their business operations.\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask_question(\"How many new engineers does the company plan to hire?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBZnNNXg6JR3",
        "outputId": "cf77c959-e21d-4b9c-d14b-d04bd3bd1a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " Question: How many new engineers does the company plan to hire?\n",
            "================================================================================\n",
            "Retrieved from: enterprise-qbr-ppt.ppt, Q3 2024 Financial Report - TechVision Industries.pdf\n",
            "\n",
            " Answer:\n",
            "The company plans to hire 500 new engineers as part of their efforts to accelerate hiring in Research and Development (R&D). This is one of the key focus areas outlined in the Q4 strategic initiatives, as mentioned in the enterprise quarterly business review presentation.\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask_question(\"What's the total units sold across all products?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRJE-bUj9fjI",
        "outputId": "37f706db-c983-44b5-d23f-d858f3714096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " Question: What's the total units sold across all products?\n",
            "================================================================================\n",
            "Retrieved from: Product_Inventory.csv, enterprise-qbr-ppt.ppt, Q3 2024 Financial Report - TechVision Industries.pdf\n",
            "\n",
            " Answer:\n",
            "To determine the total units sold across all products, we need to sum up the \"Units Sold\" figures from the provided inventory data. Here's the breakdown:\n",
            "\n",
            "1. CloudSync Pro: 2,495 units\n",
            "2. DataShield Security Suite: 1,410 units\n",
            "3. UltraBook Pro 15: 1,898 units\n",
            "4. Analytics Dashboard Pro: 750 units\n",
            "5. TeamCollab Suite: 4,240 units\n",
            "6. NetworkHub Pro 48-Port: 284 units\n",
            "7. SecureRouter Enterprise: 595 units\n",
            "8. AI Assistant Professional: 3,130 units\n",
            "\n",
            "Adding these figures together gives us the total units sold:\n",
            "\n",
            "2,495 + 1,410 + 1,898 + 750 + 4,240 + 284 + 595 + 3,130 = 14,802 units\n",
            "\n",
            "Therefore, the total units sold across all products is 14,802.\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You ask one question.  \n",
        "Behind the scenes, the system:\n",
        "- Pulls the most relevant chunks across all sources,\n",
        "- Shows you where they came from,\n",
        "- And delivers a single, coherent answer grounded in your enterprise data."
      ],
      "metadata": {
        "id": "ApH-lQRpFSJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ask_question(\"Based on the email and financial data, estimate the potential revenue risk from Global Finance Corp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oX1l4f39qoY",
        "outputId": "1082bc62-27e7-4406-ce85-8705ccd5885c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " Question: Based on the email and financial data, estimate the potential revenue risk from Global Finance Corp\n",
            "================================================================================\n",
            "Retrieved from: 98729709ec5679da.eml, Q3 2024 Financial Report - TechVision Industries.pdf\n",
            "\n",
            " Answer:\n",
            "Based on the information provided, Global Finance Corp is a significant customer for TechVision Industries, contributing over $3.2 million annually in licensing revenue. The email from Jennifer Martinez indicates a severe issue that has escalated to a high level, suggesting potential dissatisfaction and risk of losing this customer if the issue is not resolved promptly.\n",
            "\n",
            "The financial impact of the current issue is estimated at $4.7 million in lost productivity for Global Finance Corp this week, along with compliance risks and a significant increase in internal help desk tickets. These factors highlight the severity of the situation and the potential for long-term implications if not addressed.\n",
            "\n",
            "Given that Global Finance Corp has been a loyal customer for seven years, the potential revenue risk includes not only the immediate $3.2 million annual licensing fee but also the potential loss of future business and reputation damage. If the situation leads to the termination of the partnership, TechVision Industries could face a substantial revenue shortfall, particularly if Global Finance Corp decides to switch to a competitor.\n",
            "\n",
            "Additionally, considering the competitive landscape and the need for ongoing investments in cybersecurity and compliance, retaining key customers like Global Finance Corp is crucial for maintaining market share and financial stability.\n",
            "\n",
            "In summary, the potential revenue risk from Global Finance Corp could be significant, potentially exceeding the $3.2 million annual licensing fee if the relationship is damaged or lost. Immediate resolution and resource mobilization are critical to mitigate this risk and maintain the customer relationship.\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "By now you’ve seen how Unstructured can turn a messy sprawl of enterprise content into a single, queryable knowledge base.  \n",
        "Contracts from Azure Blob, decks from OneDrive, email threads from Outlook all normalized into a unified format, enriched with metadata, and stored as vector embeddings.  \n",
        "The result is a RAG pipeline that not only answers questions accurately but also explains exactly where the information came from, regardless of file type or source.\n",
        "\n",
        "This approach eliminates the headaches of building separate pipelines for every content type. Instead, you get one clean, consistent workflow that scales across your organization’s entire data landscape.\n",
        "\n",
        "---\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- **Extend your pipeline**: Add the NER Node to enhance the value of your content.\n",
        "- **Tweak retrieval logic**: Adjust chunk sizes, or add ranking models to fine‑tune what gets surfaced.\n",
        "- **Experiment with LLMs**: Swap in different models for generation (Claude, GPT‑4o, etc.) to compare style, cost, and accuracy.\n",
        "- **Add tooling**: Layer on dashboards, logs, or usage analytics to monitor how your RAG assistant performs.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Ready to unify your scattered enterprise knowledge?  \n",
        "Sign up for a [free Unstructured account](https://unstructured.io/?modal=try-for-free), connect your first sources, and try building this workflow yourself.  \n",
        "You’ll be able to go from unorganized files to a production‑ready, multi‑source RAG pipeline in an afternoon and finally get reliable, explainable answers out of your company’s data.\n"
      ],
      "metadata": {
        "id": "M0wSlcjPF51A"
      }
    }
  ]
}