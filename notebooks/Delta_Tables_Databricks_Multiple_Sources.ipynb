{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RAG with Databricks Vector Search with Context from Multiple Sources"
      ],
      "metadata": {
        "id": "_9M1N4oBB7Ab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Author: [@MariaKhalusova](https://x.com/mariaKhalusova)\n",
        "\n",
        "Last updated: Feb 6th, 2025\n"
      ],
      "metadata": {
        "id": "iMnNvQ6TCTC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook complements [this blog post](https://unstructured.io/blog/rag-seamlessly-integrating-context-from-multiple-sources-into-delta-tables-in-databricks) and illustrates how to build RAG over data that was ingested from Amazon S3 bucket and Google Drive into Databricks Delta Table with the Unstructured Platform.\n",
        "\n",
        "For the details on how to ingest data from multiple sources, preprocess it with Unstructured Platform, write the results into a Delta Table in Databricks, and how to create Databricks Vector Search Index over a Delta Table, please refer to the blog post.\n",
        "\n",
        "The notebook only covers the RAG setup."
      ],
      "metadata": {
        "id": "Mf7bd1YIDlzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "\n",
        "* [Sign for the Unstructured For Developers access](https://unstructured.io/developers). Once you do, you can log into the Platform and process up to 1000 pages per day for free for the first 14 days.\n",
        "\n",
        "* [Sign up for Databricks trial](https://login.databricks.com/?dbx_source=www&intent=SIGN_UP&rl_aid=3709974d-322e-48ff-956b-91c816014d75&tuuid=88100e00-3456-4d28-b4c0-9d3ba1e51166)\n",
        "\n",
        "* Follow the steps in [the blog post](https://unstructured.io/blog/rag-seamlessly-integrating-context-from-multiple-sources-into-delta-tables-in-databricks) to preprocess the data, set up the Databricks Vector Seach, and obtain necessary authentication details.\n",
        "\n",
        "* Obtain an OpenAI key"
      ],
      "metadata": {
        "id": "KmYA2sbUGqT_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the necessary libraries:\n",
        "* `langchain-openai` & `databricks-langchain` to set up a retriever with the Databricks Vector Search\n",
        "* `openai` to use the LLMs and embedding models from OpenAI\n"
      ],
      "metadata": {
        "id": "Szi8QCDkuYy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-openai databricks-langchain openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pYXbcFsHB8y",
        "outputId": "2e9db4b9-639f-4b7e-e6c9-c0655693c829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.6/460.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.7/412.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.3/28.3 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.4/647.4 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set your environment variables:"
      ],
      "metadata": {
        "id": "EhcYRgKgzwRS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEuIOKpiG3yO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\" # Your OpenAI API key\n",
        "os.environ[\"DATABRICKS_HOST\"] = \"\" # Host is your workspace's URL: <https://<workspace-id>.cloud.databricks.com\n",
        "os.environ[\"DATABRICKS_TOKEN\"] = \"\" # Your Personal Access Token"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a LangChain retriever for your Databricks Vector Search"
      ],
      "metadata": {
        "id": "OgOBYSfDzzPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To embed the user query, use the same embedding model that was used to generate embedding vectors stored in the vector search index. In this case, it's `text-embedding-3-small` from OpenAI."
      ],
      "metadata": {
        "id": "J_Z8ysP0z9VB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ],
      "metadata": {
        "id": "B0YC_T3al2C3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a vector store.\n",
        "\n",
        "If you followed the blog post to create the vector search index, you should have the `endpoint_name` and `index_name` ready to use here.\n",
        "\n",
        "Note, by default, similarity search only returns the primary key and text column. If you want to retrieve the custom metadata associated with the document, pass the additional columns in the columns parameter when initializing the vector store. In this example, we'll use the element `type` metadata to know whether it's a table or not, and `text_as_html` metadata to leverage the preserved table structure."
      ],
      "metadata": {
        "id": "GVvVHFUZ0La-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from databricks_langchain import DatabricksVectorSearch\n",
        "\n",
        "index_name = \"demo_workspace.default.demo_index\"  # Format: \"<catalog>.<schema>.<index-name>\"\n",
        "endpoint_name = \"uns_demo_vector_search\"\n",
        "\n",
        "vector_store = DatabricksVectorSearch(\n",
        "    endpoint=endpoint_name,\n",
        "    index_name=index_name,\n",
        "    embedding=embeddings,\n",
        "    text_column=\"text\", # The column name in the index that contains the text data\n",
        "    columns=[\"text_as_html\", \"type\"], # metadata columns to retrieve\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQtm4UNLHK6m",
        "outputId": "acd2911d-9fe4-4d72-be0a-f70d674c36bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True to VectorSearchClient().\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up this vector store as a retriever:"
      ],
      "metadata": {
        "id": "QS3Zimwx1M9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
      ],
      "metadata": {
        "id": "P5ctaLJD1UFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try it out."
      ],
      "metadata": {
        "id": "SIT7b5q91ZQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who is Brian W. Nichols?\""
      ],
      "metadata": {
        "id": "w2KNlJ5hHks_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = retriever.invoke(query)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pEm-ogdXIQ3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first retrieved document is actually a table, and we can display it. You can easily see that the second row contains the exact information that answers the question."
      ],
      "metadata": {
        "id": "9Jqi_lmc1dxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "\n",
        "display(HTML(result[0].metadata[\"text_as_html\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "-FyYnBX8Ud-u",
        "outputId": "ed3d05cd-62a3-4d59-dde1-c63fa5472ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table><tr><td>W. Rodney McMullen</td><td>63</td><td>Mr. McMullen was elected Chairman of the Board effective January 1, 2015, and Chief Executive Officer effective January 1, 2014. Prior to that, he served as President and Chief Operating Officer from August 2009 to December 2013. Prior to that he held numerous leadership roles, including Vice Chairman, Executive Vice President of Strategy, Planning and Finance, Executive Vice President and Chief Financial Officer, Senior Vice President, Group Vice President and Chief Financial Officer, Vice President, Control and Financial Services, and Vice President, Planning and Capital Management. Mr. McMullen joined Kroger in 1978 as a part-time stock clerk.</td></tr><tr><td>Brian W. Nichols</td><td>51</td><td>Mr. Nichols was elected Vice President, Corporate Controller in March 2024 and is responsible for oversight of Kroger’s Corporate Accounting and Corporate Tax departments, as well as the Company’s Accounting Centers and Accounting Modernization, Pension Investment, and Insurance and Claims teams. Prior to that, he served as Vice President, Assistant Corporate Controller from April 2021 to March 2024. From May 2018 to April 2021, Mr. Nichols served as Senior Director and Assistant Corporate Controller. Prior to that, he held several leadership roles, including Senior Manager of Corporate and External Financial Reporting and Senior Financial Analyst of SEC Reporting. Mr. Nichols joined Kroger in 2000 as Assistant Controller of the Central Division.</td></tr></table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, in this example it isn't extremely important to preserve the table structure, but in more dense tables with lots of numerical data, structure can be much more crucial.\n",
        "\n",
        "Let's build a RAG application in which when we retrieve a table, we'll actually give the LLM the html representation of said table instead of plain text."
      ],
      "metadata": {
        "id": "pCrbSTNv2GG1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we'll create a function that generates an answer given a question and retrieved documents:"
      ],
      "metadata": {
        "id": "HkAgKm2B2RzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "def generate_answer(question: str, documents: str):\n",
        "\n",
        "    prompt = \"\"\"\n",
        "You are an assistant that can answer user questions given provided context.\n",
        "Your answer should be thorough and technical.\n",
        "If you don't know the answer, or no documents are provided, say 'I do not have enough context to answer the question.'\n",
        "\"\"\"\n",
        "\n",
        "    augmented_prompt = (\n",
        "        f\"{prompt}\"\n",
        "        f\"User question: {question}\\n\\n\"\n",
        "        f\"{documents}\"\n",
        "    )\n",
        "    response = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {'role': 'system', 'content': 'You answer users questions.'},\n",
        "            {'role': 'user', 'content': augmented_prompt},\n",
        "        ],\n",
        "        model=\"gpt-4o-2024-11-20\",\n",
        "        temperature=0,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "vpgkrnBmiNoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll create a helper function that will format the retrieved documents in the following way: if we retrieved a table, then use the `text_as_html` representation of the table as a source, otherwise, just use the text:"
      ],
      "metadata": {
        "id": "sonwH95k2Ymg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "  useful_content = [doc.page_content if doc.metadata[\"type\"] != \"Table\" else doc.metadata[\"text_as_html\"] for doc in docs]\n",
        "\n",
        "  return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
        "            [\n",
        "                f\"\\n\\n===== Document {str(i)} =====\\n\" + doc\n",
        "                for i, doc in enumerate(useful_content)\n",
        "            ]\n",
        "        )"
      ],
      "metadata": {
        "id": "R9wf8CV-lWpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bring everything together:\n",
        "* Given query, invoke the retriever and get the documents\n",
        "* Format the documents to preserve the table structure\n",
        "* Pass the formatted documents and the user query to the LLM to generate an answer"
      ],
      "metadata": {
        "id": "MUsjlx_q2tXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rag(query):\n",
        "  docs = retriever.invoke(query)\n",
        "  documents = format_docs(docs)\n",
        "  answer = generate_answer(query, documents)\n",
        "  return answer"
      ],
      "metadata": {
        "id": "0QPd-Y9tnA3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the exact Kroger's operating profit in 2022?\"\n",
        "\n",
        "rag(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "5oLFaqU5ljK8",
        "outputId": "a3b85e90-203c-42f2-80b4-dce243c797ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Based on the provided documents, Kroger's operating profit for the fiscal year 2022 (52 weeks) was **$4.126 billion**. This figure is explicitly stated in the financial table in Document 2.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see that financial table from the Document 2 to confirm the answer:"
      ],
      "metadata": {
        "id": "vXYQ696c32B9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = retriever.invoke(query)"
      ],
      "metadata": {
        "id": "DcVf3dGjno3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "\n",
        "display(HTML(results[2].metadata[\"text_as_html\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "_VRks3uL3YFB",
        "outputId": "35e45da1-113d-4ac0-ca7c-ce55b569ad00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table><tr><td>(In millions, except per share amounts)</td><td>2023 (53 weeks)</td><td>2022 (52 weeks)</td><td>2021 (52 weeks)</td></tr><tr><td>Sales</td><td>§ 150,039</td><td>$ 148,258</td><td>$ 137,388</td></tr><tr><td>Operating expenses</td></tr><tr><td>Merchandise costs, including advertising, warehousing, and transportation, excluding items shown separately below</td><td>116,675</td><td>116,480</td><td>107,539</td></tr><tr><td>Operating, general and administrative</td><td>26,252</td><td>23,848</td><td>23,203</td></tr><tr><td>Rent</td><td>891</td><td>839</td><td>845</td></tr><tr><td>Depreciation and amortization</td><td>3,125</td><td>2,965</td><td>2,824</td></tr><tr><td>Operating profit</td><td>3,096</td><td>4,126</td><td>3,477</td></tr><tr><td>Other income (expense)</td></tr><tr><td>nterest expense</td><td>(441)</td><td>(535)</td><td>(571)</td></tr><tr><td>Non-service component of company-sponsored pension plan benefits (costs)</td><td>30</td><td>39</td><td>(34)</td></tr><tr><td>Gain (loss) on investments</td><td>151</td><td>(728)</td><td>(821)</td></tr><tr><td>Net earnings before income tax expense</td><td>2,836</td><td>2,902</td><td>2,051</td></tr><tr><td>Income tax expense</td><td>667</td><td>653</td><td>385</td></tr><tr><td>Net earnings including noncontrolling interests</td><td>2,169</td><td>2,249</td><td>1,666</td></tr><tr><td>Net income attributable to noncontrolling interests</td><td>5</td><td>5</td><td>11</td></tr><tr><td>Net earnings attributable to The Kroger Co.</td><td>2,164 $</td><td>2,244 $</td><td>1,655 $</td></tr><tr><td>Net earnings attributable to The Kroger Co. per basic common share</td><td>2.99 $</td><td>3.10 $</td><td>220 $</td></tr><tr><td>Average number of common shares used in basic calculation</td><td>718</td><td>718</td><td>744</td></tr><tr><td>Net earnings attributable to The Kroger Co. per diluted common share</td><td>2.96 $</td><td>3.06 $</td><td>2.17 $</td></tr></table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jE1XJF-c3bvE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}